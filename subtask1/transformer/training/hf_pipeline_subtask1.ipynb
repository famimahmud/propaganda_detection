{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y14MBnvVLci"
      },
      "source": [
        "# Persuasion Techniques in Text of Memes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T_0y77SYFxh"
      },
      "source": [
        "## Enironment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV1UUQNbZDGF"
      },
      "source": [
        "##### Disk Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLPh7rC4U0xv",
        "outputId": "709c5f98-293f-4e22-c87b-f1dff397fbb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hon4OZyGWjec"
      },
      "outputs": [],
      "source": [
        "folder_name = \"/content/drive/MyDrive/tumnlp/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmW8s6NSZKDa"
      },
      "source": [
        "##### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YG3tK5uCYXc7"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets wandb evaluate accelerate -qU sklearn_hierarchical_classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "34hMjupVXtvf"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch\n",
        "import subprocess\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QUb9QBJ1Z8D0"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
        "from transformers import EvalPrediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C71bLsbaaN_T",
        "outputId": "53c479ab-98f6-4343-e71a-dc95ef84dfb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "AVAIL_GPUS = 0\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    AVAIL_GPUS = torch.cuda.device_count()\n",
        "    print(f'There are {AVAIL_GPUS} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV9Xdol6aLRq",
        "outputId": "b45600d4-23ef-4f67-8438-4fa2956ce4bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahmudfami\u001b[0m (\u001b[33mtumnlp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "import os\n",
        "wandb.login()\n",
        "# setup wandb environment variables\n",
        "os.environ['WANDB_PROJECT'] = \"subtask1_transformer_encoder_classification\"\n",
        "os.environ['WANDB_ENTITY'] = \"tumnlp\"\n",
        "os.environ[\"WANDB_LOG_MODEL\"]= \"end\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5ptOdklcyQE"
      },
      "source": [
        "## Pre-trained Transformer Name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "N6r0SluLcdKz"
      },
      "outputs": [],
      "source": [
        "checkpoint = \"bert-base-cased\"\n",
        "#checkpoint = \"xlm-roberta-base\"\n",
        "#checkpoint = \"xlnet-base-cased\"\n",
        "#checkpoint = \"microsoft/deberta-v3-base\"\n",
        "#checkpoint = \"albert-base-v2\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oii8V3FvjSDx"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2XKmbh2JjROn"
      },
      "outputs": [],
      "source": [
        "dataset_folder = folder_name + \"datasets/json_data/subtask1/\"\n",
        "train_st1 = dataset_folder + \"train.json\"\n",
        "val_st1 = dataset_folder + \"validation.json\"\n",
        "dev_st1 = dataset_folder + \"dev_unlabeled.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vvB8izwp8iJT"
      },
      "outputs": [],
      "source": [
        "train_data1=pd.read_json(train_st1)\n",
        "val_data1 = pd.read_json(val_st1)\n",
        "dev_data1 = pd.read_json(dev_st1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ZVomchr08yCn",
        "outputId": "087a38b0-0ebb-4c83-d6b5-218efbc86e09"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-875e672a-bd50-4d1b-80a7-88f4f9bb162f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "      <th>link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>65635</td>\n",
              "      <td>THIS IS WHY YOU NEED\\n\\nA SHARPIE WITH YOU AT ...</td>\n",
              "      <td>[Black-and-white Fallacy/Dictatorship]</td>\n",
              "      <td>https://www.facebook.com/photo/?fbid=402355213...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67927</td>\n",
              "      <td>GOOD NEWS!\\n\\nNAZANIN ZAGHARI-RATCLIFFE AND AN...</td>\n",
              "      <td>[Loaded Language, Glittering generalities (Vir...</td>\n",
              "      <td>https://www.facebook.com/amnesty/photos/531198...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>68031</td>\n",
              "      <td>PAING PHYO MIN IS FREE!</td>\n",
              "      <td>[]</td>\n",
              "      <td>https://www.facebook.com/amnesty/photos/427419...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>77490</td>\n",
              "      <td>Move your ships away!\\n\\noooook\\n\\nMove your s...</td>\n",
              "      <td>[]</td>\n",
              "      <td>https://www.facebook.com/rightpatriots/photos/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>67641</td>\n",
              "      <td>WHEN YOU'RE THE FBI, THEY LET YOU DO IT.</td>\n",
              "      <td>[Thought-terminating cliché]</td>\n",
              "      <td>https://www.facebook.com/AddictingInfoOrg/phot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6995</th>\n",
              "      <td>67360</td>\n",
              "      <td>If your doctor prescribes you medication witho...</td>\n",
              "      <td>[Loaded Language, Causal Oversimplification, T...</td>\n",
              "      <td>https://www.facebook.com/TheControversia/photo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6996</th>\n",
              "      <td>70579</td>\n",
              "      <td>DEFENDS TRUMP. \\nMADE ALLEGATIONS OF ELECTION ...</td>\n",
              "      <td>[Loaded Language, Whataboutism]</td>\n",
              "      <td>https://www.facebook.com/PatriotFetch/photos/p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6997</th>\n",
              "      <td>70305</td>\n",
              "      <td>I'm having trouble selling our incredibly enor...</td>\n",
              "      <td>[]</td>\n",
              "      <td>https://www.facebook.com/PatriotFetch/photos/p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6998</th>\n",
              "      <td>77769</td>\n",
              "      <td>I'm so happy we live in a world without slaver...</td>\n",
              "      <td>[]</td>\n",
              "      <td>https://www.facebook.com/communism101/photos/5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6999</th>\n",
              "      <td>67944</td>\n",
              "      <td>Reminder\\nWomen's rights are human rights.\\nAl...</td>\n",
              "      <td>[Slogans]</td>\n",
              "      <td>https://www.facebook.com/amnesty/photos/509490...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7000 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-875e672a-bd50-4d1b-80a7-88f4f9bb162f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-875e672a-bd50-4d1b-80a7-88f4f9bb162f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-875e672a-bd50-4d1b-80a7-88f4f9bb162f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-59c5dede-bf4f-4128-958e-712427994228\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-59c5dede-bf4f-4128-958e-712427994228')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-59c5dede-bf4f-4128-958e-712427994228 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         id                                               text  \\\n",
              "0     65635  THIS IS WHY YOU NEED\\n\\nA SHARPIE WITH YOU AT ...   \n",
              "1     67927  GOOD NEWS!\\n\\nNAZANIN ZAGHARI-RATCLIFFE AND AN...   \n",
              "2     68031                            PAING PHYO MIN IS FREE!   \n",
              "3     77490  Move your ships away!\\n\\noooook\\n\\nMove your s...   \n",
              "4     67641           WHEN YOU'RE THE FBI, THEY LET YOU DO IT.   \n",
              "...     ...                                                ...   \n",
              "6995  67360  If your doctor prescribes you medication witho...   \n",
              "6996  70579  DEFENDS TRUMP. \\nMADE ALLEGATIONS OF ELECTION ...   \n",
              "6997  70305  I'm having trouble selling our incredibly enor...   \n",
              "6998  77769  I'm so happy we live in a world without slaver...   \n",
              "6999  67944  Reminder\\nWomen's rights are human rights.\\nAl...   \n",
              "\n",
              "                                                 labels  \\\n",
              "0                [Black-and-white Fallacy/Dictatorship]   \n",
              "1     [Loaded Language, Glittering generalities (Vir...   \n",
              "2                                                    []   \n",
              "3                                                    []   \n",
              "4                          [Thought-terminating cliché]   \n",
              "...                                                 ...   \n",
              "6995  [Loaded Language, Causal Oversimplification, T...   \n",
              "6996                    [Loaded Language, Whataboutism]   \n",
              "6997                                                 []   \n",
              "6998                                                 []   \n",
              "6999                                          [Slogans]   \n",
              "\n",
              "                                                   link  \n",
              "0     https://www.facebook.com/photo/?fbid=402355213...  \n",
              "1     https://www.facebook.com/amnesty/photos/531198...  \n",
              "2     https://www.facebook.com/amnesty/photos/427419...  \n",
              "3     https://www.facebook.com/rightpatriots/photos/...  \n",
              "4     https://www.facebook.com/AddictingInfoOrg/phot...  \n",
              "...                                                 ...  \n",
              "6995  https://www.facebook.com/TheControversia/photo...  \n",
              "6996  https://www.facebook.com/PatriotFetch/photos/p...  \n",
              "6997  https://www.facebook.com/PatriotFetch/photos/p...  \n",
              "6998  https://www.facebook.com/communism101/photos/5...  \n",
              "6999  https://www.facebook.com/amnesty/photos/509490...  \n",
              "\n",
              "[7000 rows x 4 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFMn_A_MAqTE"
      },
      "source": [
        "#### Load into huggingface datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGrha9Za_JVR",
        "outputId": "179851e8-dff6-42a5-fb77-639b4c318609"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['labels', 'text', 'link', 'id'],\n",
              "        num_rows: 7000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['labels', 'text', 'link', 'id'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "data_files = {\"train\": train_st1, \"validation\": val_st1}\n",
        "st1_dataset = load_dataset(\"json\",data_files=data_files)\n",
        "st1_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON7zZsHeE1_H"
      },
      "source": [
        "##### Discard all samples without persuasion technique\n",
        "*Or keep them as non-persuasive samples?*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-hD7cGID0dr",
        "outputId": "c669014b-0030-43ea-800b-8c271401b5e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['labels', 'text', 'link', 'id'],\n",
              "        num_rows: 5736\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['labels', 'text', 'link', 'id'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "st1_dataset['train'] = st1_dataset['train'].filter(lambda x : len(x['labels']) != 0)\n",
        "st1_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4B9qSGfpIdEe",
        "outputId": "a847ded1-7ac8-4109-86a9-5e1b2da637b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "techniques = [['Black-and-white Fallacy/Dictatorship', 'Loaded Language',\n",
        "       'Glittering generalities (Virtue)', 'Thought-terminating cliché',\n",
        "       'Whataboutism', 'Slogans', 'Causal Oversimplification', 'Smears',\n",
        "       'Name calling/Labeling', 'Appeal to authority',\n",
        "       'Exaggeration/Minimisation', 'Repetition', 'Flag-waving',\n",
        "       'Appeal to fear/prejudice', 'Reductio ad hitlerum', 'Doubt',\n",
        "       \"Misrepresentation of Someone's Position (Straw Man)\",\n",
        "       'Obfuscation, Intentional vagueness, Confusion', 'Bandwagon',\n",
        "       'Presenting Irrelevant Data (Red Herring)']]\n",
        "num_labels = len(techniques[0])\n",
        "num_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmg1FJOHcpxs"
      },
      "source": [
        "### Preprocess Multi-Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "4OzCS8Unctn-",
        "outputId": "005a4de1-8ebf-4181-dc21-b7665bcbbdfc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiLabelBinarizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiLabelBinarizer</label><div class=\"sk-toggleable__content\"><pre>MultiLabelBinarizer()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "MultiLabelBinarizer()"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlb = MultiLabelBinarizer()\n",
        "mlb.fit(techniques)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgAQXgvkKjW_"
      },
      "source": [
        "#### Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc5lQuWUJ83q",
        "outputId": "3121dbfc-4ae5-4a05-c025-2e341751ccf7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['labels', 'text', 'link', 'id', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 5736\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['labels', 'text', 'link', 'id', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "def tokenize_function(examples):\n",
        "    encoding = tokenizer(examples[\"text\"], truncation=True)\n",
        "    encoding['labels'] = mlb.transform(examples['labels']).astype(np.float32).tolist()\n",
        "    return encoding\n",
        "\n",
        "tokenized_datasets = st1_dataset.map(tokenize_function, batched=True)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "tokenized_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_PUUCWbQ8Cc"
      },
      "source": [
        "Test Output tokenized Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IfE7Tk_VdUG",
        "outputId": "29d0e9b0-1e41-4c79-aacb-64b7acfbfc02"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'labels': torch.Size([8, 20]),\n",
              " 'input_ids': torch.Size([8, 80]),\n",
              " 'attention_mask': torch.Size([8, 80])}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "samples = tokenized_datasets[\"train\"][:8]\n",
        "samples = {k: v for k, v in samples.items() if k not in [\"id\", \"text\", \"link\"]}\n",
        "batch = data_collator(samples)\n",
        "{k: v.shape for k, v in batch.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izyqvy-5RjPs"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Ubp6MPU6Mew9"
      },
      "outputs": [],
      "source": [
        "def save_json(data, file_path):\n",
        "    with open(file_path, 'w') as f:\n",
        "        json.dump(data, f)\n",
        "\n",
        "def create_json_output(y_pred, y_true):\n",
        "    # Transfrom numeric labels into textual labels\n",
        "    y_pred = mlb.inverse_transform(y_pred)\n",
        "    y_true = mlb.inverse_transform(y_true)\n",
        "    # Convert y_true and y_pred to the required JSON format\n",
        "    pred_json = [{\"id\": str(idx), \"labels\": pred_row} for idx, pred_row in enumerate(y_pred)]\n",
        "    true_json = [{\"id\": str(idx), \"labels\": true_row} for idx, true_row in enumerate(y_true)]\n",
        "\n",
        "    # Save to json files\n",
        "    predictions_file = folder_name + \"subtask1/output/tmp/predictions.json\"\n",
        "    gold_labels_file= folder_name + \"subtask1/output/tmp/gold_labels.json\"\n",
        "    save_json(pred_json, predictions_file)\n",
        "    save_json(true_json, gold_labels_file)\n",
        "    return predictions_file, gold_labels_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4o53t_w_baxe"
      },
      "outputs": [],
      "source": [
        "def calculate_hierarchical_metrics(predictions_file, gold_labels_file):\n",
        "    # Run the scoring script\n",
        "    scorer = folder_name + \"subtask1/subtask_1_2a.py\"\n",
        "    command = f'python3 {scorer} --gold_file_path {gold_labels_file} --pred_file_path {predictions_file}'\n",
        "    result = subprocess.run(command, shell=True, check=True, stdout=subprocess.PIPE, text=True)\n",
        "    output = result.stdout.strip()\n",
        "\n",
        "    # Parse the output\n",
        "    parts = output.split('\\t')\n",
        "    f1_h = float(parts[0].split('=')[1])\n",
        "    prec_h = float(parts[1].split('=')[1])\n",
        "    rec_h = float(parts[2].split('=')[1])\n",
        "\n",
        "    return f1_h, prec_h, rec_h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KXEoj4KZ_m3i"
      },
      "outputs": [],
      "source": [
        "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
        "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
        "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
        "    sigmoid = torch.nn.Sigmoid()\n",
        "    probs = sigmoid(torch.Tensor(predictions))\n",
        "    # next, use threshold to turn them into integer predictions\n",
        "    y_pred = np.zeros(probs.shape)\n",
        "    y_pred[np.where(probs >= threshold)] = 1\n",
        "    y_true = labels\n",
        "\n",
        "    # Create Json Output file\n",
        "    predictions_file, gold_labels_file = create_json_output(y_pred, y_true)\n",
        "\n",
        "    # compute metrics\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    f1_h, prec_h, rec_h = calculate_hierarchical_metrics(predictions_file, gold_labels_file)\n",
        "\n",
        "\n",
        "    # return as dictionary\n",
        "    metrics = {'f1_hierarchical': f1_h,\n",
        "               'precision_hierarchical': prec_h,\n",
        "               'recall_hierarchical': rec_h,\n",
        "               'f1_micro': f1_micro_average,\n",
        "               'accuracy': accuracy,\n",
        "               }\n",
        "    return metrics\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    preds = p.predictions[0] if isinstance(p.predictions,\n",
        "            tuple) else p.predictions\n",
        "    result = multi_label_metrics(\n",
        "        predictions=preds,\n",
        "        labels=p.label_ids)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XG1KSisvSyaK",
        "outputId": "dcbb6863-baf2-4f62-862a-2b0b58aca550"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=len(techniques[0]), problem_type=\"multi_label_classification\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "UD-z16wQXM_s"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "output_folder = folder_name + \"subtask1/output\"\n",
        "training_args = TrainingArguments(\n",
        "    report_to = 'wandb',                    # enable logging to W&B\n",
        "    run_name = 'bert-base_cased_2',          # name of the W&B run\n",
        "    load_best_model_at_end = True,\n",
        "    output_dir = output_folder,\n",
        "    overwrite_output_dir = True,\n",
        "    evaluation_strategy = 'steps',\n",
        "    learning_rate = 5e-5,\n",
        "    num_train_epochs = 50,\n",
        "    #max_steps = 50000,\n",
        "    logging_steps = 100,\n",
        "    eval_steps = 1000,\n",
        "    save_steps = 30000,\n",
        "    metric_for_best_model = 'f1_hierarchical',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "W3Sp3L75UDhm"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "-ODQhIGZUz1e",
        "outputId": "5c25af88-c41b-478b-8f2b-d064c90c4675"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231109_171545-ao1qk4zo</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/tumnlp/subtask1_transformer_encoder_classification/runs/ao1qk4zo' target=\"_blank\">xlm-roberta-base_1</a></strong> to <a href='https://wandb.ai/tumnlp/subtask1_transformer_encoder_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/tumnlp/subtask1_transformer_encoder_classification' target=\"_blank\">https://wandb.ai/tumnlp/subtask1_transformer_encoder_classification</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/tumnlp/subtask1_transformer_encoder_classification/runs/ao1qk4zo' target=\"_blank\">https://wandb.ai/tumnlp/subtask1_transformer_encoder_classification/runs/ao1qk4zo</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='774' max='35850' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  774/35850 03:13 < 2:26:10, 4.00 it/s, Epoch 1.08/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BzBbuUm4qBZ"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3brJadwlGV1h"
      },
      "source": [
        "### Predict validation set and create output json file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05TokdTeGECA"
      },
      "outputs": [],
      "source": [
        "trainer_predictions = trainer.predict(tokenized_datasets[\"validation\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-QHy67aN_kI"
      },
      "outputs": [],
      "source": [
        "# Transform logits into probabilities\n",
        "predicted_logits = trainer_predictions.predictions\n",
        "sigmoid = torch.nn.Sigmoid()\n",
        "predicted_logits_tensor = torch.from_numpy(predicted_logits)\n",
        "probs = sigmoid(predicted_logits_tensor.squeeze())\n",
        "# Get predictions that have higher probability than threshold\n",
        "threshold = 0.5\n",
        "predictions = (probs > threshold).int()\n",
        "# Get labels in text form\n",
        "predicted_labels = mlb.inverse_transform(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QqM-xf5WqJm"
      },
      "source": [
        "### Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAcjXrzMTXl3"
      },
      "outputs": [],
      "source": [
        "predicted_labels[20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rx4TAXcHVLPu"
      },
      "outputs": [],
      "source": [
        "st1_dataset['validation']['labels'][20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1skBuN0VGdnP"
      },
      "source": [
        "### Create Prediction Output File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzTFEscmjf3M"
      },
      "outputs": [],
      "source": [
        "predicted_labels = list(map(list, predicted_labels))\n",
        "val_preds = val_data1.drop(['labels', 'link', 'text'], axis=1)\n",
        "val_preds.insert(1,'labels',pd.Series(predicted_labels))\n",
        "val_preds['id'] = val_preds['id'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFayQKC9iUIC"
      },
      "outputs": [],
      "source": [
        "val_preds_output = val_preds.to_dict(orient='records')\n",
        "val_output_file = folder_name + \"subtask1/output/validation_output.json\"\n",
        "with open(val_output_file, \"w\") as output_file:\n",
        "    json.dump(val_preds_output, output_file, indent=2,ensure_ascii=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt1GzHXGrgCN"
      },
      "source": [
        "### Evaluate using the scorer script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02UlyW_2rg7P"
      },
      "outputs": [],
      "source": [
        "scorer = folder_name + \"subtask1/subtask_1_2a.py\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZ6bPGIuJ-a3"
      },
      "outputs": [],
      "source": [
        "command = f'python3 {scorer} --gold_file_path {val_st1} --pred_file_path {val_output_file}'\n",
        "\n",
        "# Run the command and get output\n",
        "result = subprocess.run(command, shell=True, check=True, stdout=subprocess.PIPE, text=True)\n",
        "\n",
        "# Extract the command output\n",
        "output = result.stdout.strip()\n",
        "\n",
        "# Parse the f1, precision, and recall values from the output\n",
        "parts = output.split('\\t')\n",
        "f1_h = parts[0].split('=')[1]\n",
        "prec_h = parts[1].split('=')[1]\n",
        "rec_h = parts[2].split('=')[1]\n",
        "\n",
        "# Convert to float if necessary\n",
        "f1_h = float(f1_h)\n",
        "prec_h = float(prec_h)\n",
        "rec_h = float(rec_h)\n",
        "\n",
        "hierarchical_metrics = {\"f1_hierarchical\": f1_h, \"precision_hierarchical\": prec_h, \"recall_hierarchical\": rec_h}\n",
        "hierarchical_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rgKAeIL58Sm"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6g11nAtueWUy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
