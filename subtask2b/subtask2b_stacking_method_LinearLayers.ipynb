{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dU8lES-HiQHE"
   },
   "source": [
    "## Env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M_z85btlfVSY",
    "outputId": "4ead1d75-2a8c-477c-f30f-e603ae67f6f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eKqXPIS-jWOf",
    "outputId": "4a0dd6d0-9a3c-455c-cba9-ad4b765c7fa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Thu Jan 25 23:17:56 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   36C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# For emptying trash after each run\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from googleapiclient.discovery import build\n",
    "drive_service = build('drive', 'v3')\n",
    "drive_service.files().emptyTrash().execute()\n",
    "!pwd\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fEoAZr2jdYV"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "deheGLB8jglV"
   },
   "outputs": [],
   "source": [
    "folder_name = \"/home/nlp-lab-ws23/nlp_praktikum/persuasion_technique_detection/\" #\"/content/drive/MyDrive/persuasion_technique_detection/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WhEmv5JrjkZA"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers datasets wandb evaluate accelerate -qU sklearn_hierarchical_classification sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_oAACjMfjnfd"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import subprocess\n",
    "import json\n",
    "import warnings\n",
    "import shutil\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer, ViTFeatureExtractor\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset,load_dataset,DatasetDict,concatenate_datasets\n",
    "import datasets\n",
    "import os\n",
    "from torch.nn.functional import sigmoid\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from datasets import concatenate_datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from transformers import Trainer\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoConfig,ViTForImageClassification, AutoModelForSequenceClassification, \\\n",
    "AutoImageProcessor,AutoTokenizer,AutoFeatureExtractor,ViTImageProcessor,ViTConfig, BertConfig, VisionTextDualEncoderConfig, VisionTextDualEncoderModel,CLIPImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Esf7JoifjrV5",
    "outputId": "9528e38e-aada-49a0-ac2d-c2a54e3204e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 3080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "AVAIL_GPUS = 0\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    AVAIL_GPUS = torch.cuda.device_count()\n",
    "    print(f'There are {AVAIL_GPUS} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "namJ79hAjvvQ"
   },
   "source": [
    "## Login WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qEAikZgDjtj5",
    "outputId": "59050093-1ba9-40d9-f781-c12f8bbac0a3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahmudfami\u001b[0m (\u001b[33mtumnlp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import os\n",
    "\n",
    "#wandb.login(relogin=True)\n",
    "wandb.login()\n",
    "\n",
    "# setup wandb environment variables\n",
    "os.environ['WANDB_PROJECT'] = \"subtask2b\"\n",
    "os.environ['WANDB_ENTITY'] = \"tumnlp\"\n",
    "os.environ[\"WANDB_LOG_MODEL\"]= \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Kd_G2X1-j1uB"
   },
   "outputs": [],
   "source": [
    "text_checkpoint = \"vinai/bertweet-large\"\n",
    "img_checkpoint= \"google/vit-base-patch32-224-in21k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "N-2F4_ljj6bu"
   },
   "outputs": [],
   "source": [
    "summary_dir_path = folder_name + \"subtask2b/new_summaries/summary_\" + text_checkpoint.replace(\"/\",\"_\")+\"_\"+img_checkpoint.replace(\"/\",\"_\")+\"_STACKING_LinearLayers_VALfortraining/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdDPD3uXkMWY"
   },
   "source": [
    "## Preprocess text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zXwsWCmbkQeT",
    "outputId": "a9ca9434-9326-468b-e39e-c2c7c6c91a5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 150 300\n"
     ]
    }
   ],
   "source": [
    "val_path=\"data/subtask2b/val.json\"\n",
    "train_path=\"data/subtask2b/train.json\"\n",
    "test_path=\"data/subtask2b/dev_unlabeled.json\"\n",
    "\n",
    "with open(folder_name+val_path) as f:\n",
    "  d = json.load(f)\n",
    "  val=pd.DataFrame.from_dict(d)\n",
    "  labels=val[\"label\"]\n",
    "  num_label=[int(el==\"propagandistic\") for el in labels]\n",
    "  val[\"num_label\"]=num_label\n",
    "  val=val.drop(columns=['label'])\n",
    "  val_set=val.rename(columns={\"num_label\": \"label\"})\n",
    "\n",
    "with open(folder_name+train_path) as f:\n",
    "  d = json.load(f)\n",
    "  train=pd.DataFrame.from_dict(d)\n",
    "  labels=train[\"label\"]\n",
    "  num_label=[int(el==\"propagandistic\") for el in labels]\n",
    "  train[\"num_label\"]=num_label\n",
    "  train=train.drop(columns=['label'])\n",
    "  train_set=train.rename(columns={\"num_label\": \"label\"})\n",
    "  #mask = train_set['image'] == \"prop_meme_24871.png\"\n",
    "  #train_set = train_set[~mask]\n",
    "\n",
    "with open(folder_name+test_path) as f:\n",
    "  d = json.load(f)\n",
    "  dev_unlabeled_set=pd.DataFrame.from_dict(d)\n",
    "\n",
    "label2num={\"non_propagandistic\":0,\"propagandistic\":1}\n",
    "num2label={0:\"non_propagandistic\",1:\"propagandistic\"}\n",
    "\n",
    "print(len(train_set),len(val_set),len(dev_unlabeled_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jrZSxQnaldT8"
   },
   "outputs": [],
   "source": [
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x,y=None):\n",
    "      super().__init__()\n",
    "      self.x=x\n",
    "      self.y=y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      if self.y is not None:\n",
    "        return np.array(self.x[idx]).astype(np.float32),np.array(self.y[idx]).astype(np.float32)\n",
    "      else:\n",
    "        return np.array(self.x[idx]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "V7sKojuVkswn"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, dataset_type,image_processor):\n",
    "        super().__init__()\n",
    "        self.ids=list(dataset[\"id\"])\n",
    "        self.texts = list(dataset[\"text\"])\n",
    "        self.image_paths = list(dataset[\"image\"])\n",
    "        if dataset_type==\"train\" or dataset_type==\"val\":\n",
    "          self.labels = dataset[\"label\"].astype(int).tolist()\n",
    "        self.image_processor = image_processor\n",
    "        self.dataset_type=dataset_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.dataset_type==\"train\":\n",
    "          image_path=folder_name+ \"data/subtask2b/subtask2b_images/train/\"+ self.image_paths[idx]\n",
    "        elif self.dataset_type==\"val\":\n",
    "          image_path=folder_name+ \"data/subtask2b/subtask2b_images/val/\"+ self.image_paths[idx]\n",
    "        else:\n",
    "          image_path=folder_name+ \"data/subtask2b/subtask2b_images/dev/\"+ self.image_paths[idx]\n",
    "\n",
    "        image_input = self.image_processor(images=Image.open(image_path).convert(\"RGB\"), return_tensors=\"pt\")\n",
    "\n",
    "        if self.dataset_type==\"train\" or self.dataset_type==\"val\":\n",
    "          label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "          return self.ids[idx],self.texts[idx],image_input,label\n",
    "        else:\n",
    "          return self.ids[idx],self.texts[idx],image_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Unw0tBzsyGU",
    "outputId": "0ee04133-38a4-41b5-a1d1-59b718451258"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlp-lab-ws23/nlp_praktikum/nlp_praktikum_env/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(text_checkpoint)\n",
    "text_model = AutoModel.from_pretrained(text_checkpoint)\n",
    "\n",
    "# change image processor for different models\n",
    "image_processor = ViTImageProcessor.from_pretrained(img_checkpoint)  #'google/vit\n",
    "#image_processor = CLIPImageProcessor.from_pretrained(img_checkpoint) #\"openai/clip\n",
    "#image_processor = AutoImageProcessor.from_pretrained(img_checkpoint)\n",
    "image_model = AutoModel.from_pretrained(img_checkpoint)\n",
    "#image_model.config, text_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-y3I4Vv1o2PA"
   },
   "outputs": [],
   "source": [
    "#image_model.config.hidden_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "SPXWTMLLgjZv"
   },
   "outputs": [],
   "source": [
    "class LinearLayers(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(LinearLayers, self).__init__()\n",
    "    self.lin1=nn.Linear(4,16)\n",
    "    self.lin2=nn.Linear(16,1)\n",
    "    self.relu=nn.ReLU()\n",
    "\n",
    "  def forward(self,x):\n",
    "    x=self.lin1(x)\n",
    "    x=self.relu(x)\n",
    "    x=self.lin2(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QP4AyUorl6jn"
   },
   "outputs": [],
   "source": [
    "class TextImageBinaryClassifier(nn.Module):\n",
    "    def __init__(self, text_model, image_model):\n",
    "        super(TextImageBinaryClassifier, self).__init__()\n",
    "        self.text_model = text_model\n",
    "        self.image_model = image_model\n",
    "\n",
    "        #image_hidden_size=image_model.config.projection_dim #openai/vit\n",
    "        image_hidden_size=image_model.config.hidden_size # google/vit\n",
    "        #image_hidden_size=image_model.config.hidden_sizes[-1] #resnet\n",
    "        #image_hidden_size=image_model.config.hidden_dim # efficientnet\n",
    "\n",
    "        self.lin1 = nn.Linear(text_model.config.hidden_size + image_hidden_size,512)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.lin2=nn.Linear(512,1)\n",
    "\n",
    "    def forward(self, text_input, image_input):\n",
    "        # Text encoding\n",
    "        text_outputs = self.text_model(**text_input)\n",
    "\n",
    "        text_embedding = text_outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "        # Image encoding\n",
    "        try:\n",
    "          #image_embedding=self.image_model.get_image_features(**image_input) #  \"openai/clip\n",
    "\n",
    "          image_outputs = self.image_model(**image_input)  #'google/vit\n",
    "          image_embedding = image_outputs.last_hidden_state.mean(dim=1) #'google/vit\n",
    "\n",
    "          #image_outputs = self.image_model(**image_input) # resnet, efficientnet\n",
    "          #image_embedding=image_outputs.last_hidden_state # resnet, efficientnet\n",
    "          #image_embedding = F.adaptive_avg_pool2d(image_embedding, (1, 1)).view(image_embedding.size(0), image_embedding.size(1)) # resnet, efficientnet\n",
    "\n",
    "        except Exception as e:\n",
    "          print(\"error:\",str(e))\n",
    "\n",
    "\n",
    "        # Concatenate text and image embeddings\n",
    "        combined_embedding = torch.cat((text_embedding, image_embedding), dim=1)\n",
    "\n",
    "\n",
    "        x = self.lin1(combined_embedding)\n",
    "        x=self.relu(x)\n",
    "        logits=self.lin2(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dO1VOZ8XqiiL"
   },
   "outputs": [],
   "source": [
    "# Create a custom dataset\n",
    "train_dataset = CustomDataset(train_set,\"train\", image_processor)\n",
    "val_dataset = CustomDataset(val_set,\"val\", image_processor)\n",
    "test_dataset = CustomDataset(dev_unlabeled_set,\"test\", image_processor)\n",
    "\n",
    "batch_size=2\n",
    "num_workers=2\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,num_workers=num_workers,pin_memory=True)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers=num_workers,pin_memory=True,drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,num_workers=num_workers,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aLh0NGcmazEG",
    "outputId": "ace9ead6-8df3-4ad1-a62b-8a02c60132c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 1200 val size: 150 test size: 300\n"
     ]
    }
   ],
   "source": [
    "print(\"train size:\",len(train_set),\"val size:\",len(val_set),\"test size:\",len(dev_unlabeled_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIYgbiz9IBGr"
   },
   "source": [
    "## Training - Meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "GtW5ka24foah"
   },
   "outputs": [],
   "source": [
    "def write_json(path,data,file_name=\"summary.json\"):\n",
    "  if not isinstance(data, dict):\n",
    "    data = data.to_dict(\"records\")\n",
    "  if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "  with open(path+file_name, \"w\") as output_file:\n",
    "      json.dump(data, output_file, indent=2,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "difE4cnFJyls"
   },
   "outputs": [],
   "source": [
    "best_image_model= \"best_model_google_vit-base-patch32-224-in21k-subtask2b-memes-IMAGEONLY_3e-06learningRate:v0\"\n",
    "#best_text_model= \"best_model_vinai_bertweet-large-TEXTONLY-subtask2b-memes_1e-06learningRate:v1\"\n",
    "best_text_model=\"best_model_microsoft_deberta-v3-large-TEXTONLY-subtask2b-memes_0.0005learningRate:v0\"\n",
    "best_meta_model={\n",
    "    \"best_image_model\":best_image_model,\n",
    "    \"best_text_model\":best_text_model,\n",
    "    \"best_meta\":None,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A82jr3y8sxvV",
    "outputId": "4e3b6515-d58a-4bd3-baad-4307af18818c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact best_model_google_vit-base-patch32-224-in21k-subtask2b-memes-IMAGEONLY_3e-06learningRate:v0, 333.73MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact best_model_microsoft_deberta-v3-large-TEXTONLY-subtask2b-memes_0.0005learningRate:v0, 1659.85MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:2.0\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['pooler.dense.bias', 'classifier.weight', 'classifier.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch32-224-in21k and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "artifact=api.artifact(best_image_model)\n",
    "best_image_model_dir_=artifact.download()\n",
    "best_image_model_dir = os.path.join(best_image_model_dir_, best_image_model.split(\":\")[0]+\".pth\")\n",
    "image_model_state_dict = torch.load(best_image_model_dir)\n",
    "\n",
    "artifact=api.artifact(best_text_model)\n",
    "best_text_model_dir_=artifact.download()\n",
    "best_text_model_dir = os.path.join(best_text_model_dir_, best_text_model.split(\":\")[0]+\".pth\" )\n",
    "text_model_state_dict = torch.load(best_text_model_dir)\n",
    "\n",
    "\n",
    "text_model = AutoModelForSequenceClassification.from_pretrained(text_checkpoint, num_labels=2 ,id2label=num2label,label2id=label2num,ignore_mismatched_sizes=True)\n",
    "text_model.load_state_dict(text_model_state_dict)\n",
    "text_model.cuda()\n",
    "text_model.eval()\n",
    "image_model = ViTForImageClassification.from_pretrained(img_checkpoint)\n",
    "image_model.load_state_dict(image_model_state_dict)\n",
    "image_model.cuda()\n",
    "image_model.eval()\n",
    "\n",
    "image_preds_train=[]\n",
    "text_preds_train=[]\n",
    "y_train=[]\n",
    "\n",
    "image_preds_val=[]\n",
    "text_preds_val=[]\n",
    "text_probs_val=[]\n",
    "image_probs_val=[]\n",
    "y_val=[]\n",
    "\n",
    "image_preds_test=[]\n",
    "text_preds_test=[]\n",
    "text_probs_test=[]\n",
    "image_probs_test=[]\n",
    "\n",
    "\n",
    "\"\"\"for id, text_input, image_input, label in train_dataloader:\n",
    "\n",
    "  text_input = tokenizer(text_input, return_tensors=\"pt\",truncation=True, padding=True,max_length=512)\n",
    "  text_input=text_input.to(\"cuda\")\n",
    "  image_input['pixel_values']=image_input['pixel_values'].squeeze(1)\n",
    "  image_input=image_input.to(\"cuda\")\n",
    "\n",
    "  text_preds_train += sigmoid(text_model(**text_input).logits).detach().cpu().tolist()\n",
    "  image_preds_train += sigmoid(image_model(**image_input).logits).detach().cpu().tolist()\n",
    "  y_train+=label.detach().cpu().tolist()\"\"\"\n",
    "#print(text_preds_train)\n",
    "\n",
    "for id, text_input, image_input, label in val_dataloader:\n",
    "\n",
    "  text_input = tokenizer(text_input, return_tensors=\"pt\",truncation=True, padding=True,max_length=512)\n",
    "  text_input=text_input.to(\"cuda\")\n",
    "  image_input['pixel_values']=image_input['pixel_values'].squeeze(1)\n",
    "  image_input=image_input.to(\"cuda\")\n",
    "\n",
    "  text_preds=sigmoid(text_model(**text_input).logits)\n",
    "  image_preds=sigmoid(image_model(**image_input).logits)\n",
    "\n",
    "  text_probs_val.extend(text_preds.detach().cpu().tolist())\n",
    "  image_probs_val.extend(image_preds.detach().cpu().tolist())\n",
    "\n",
    "  text_preds_val.extend((text_preds > 0.5).int().cpu().tolist())\n",
    "  image_preds_val.extend((image_preds> 0.5).int().cpu().tolist())\n",
    "  y_val+=label.detach().cpu().tolist()\n",
    "\n",
    "for id, text_input, image_input in test_dataloader:\n",
    "\n",
    "  text_input = tokenizer(text_input, return_tensors=\"pt\",truncation=True, padding=True,max_length=512)\n",
    "  text_input=text_input.to(\"cuda\")\n",
    "  image_input['pixel_values']=image_input['pixel_values'].squeeze(1)\n",
    "  image_input=image_input.to(\"cuda\")\n",
    "  text_preds=sigmoid(text_model(**text_input).logits)\n",
    "  image_preds=sigmoid(image_model(**image_input).logits)\n",
    "\n",
    "  text_probs_test.extend(text_preds.detach().cpu().tolist())\n",
    "  image_probs_test.extend(image_preds.detach().cpu().tolist())\n",
    "\n",
    "  text_preds_test.extend((text_preds > 0.5).int().cpu().tolist())\n",
    "  image_preds_test.extend((image_preds> 0.5).int().cpu().tolist())\n",
    "\n",
    "#train_x=np.column_stack((image_preds_train,text_preds_train))\n",
    "val_x=np.column_stack((image_preds_val,text_preds_val))\n",
    "test_x=np.column_stack((image_preds_test,text_preds_test))\n",
    "lb = LabelBinarizer()\n",
    "#y_train=lb.fit_transform(y_train)\n",
    "y_val=lb.fit_transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "rDHmIwD_5WWW"
   },
   "outputs": [],
   "source": [
    "test_prob_x=np.column_stack((image_probs_test,text_probs_test))\n",
    "val_prob_x=np.column_stack((image_probs_val,text_probs_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "UJ9r8DWVmUrR"
   },
   "outputs": [],
   "source": [
    "#val_simple_dataset=SimpleDataset(val_x,y_val)\n",
    "#test_simple_dataset=SimpleDataset(test_x)\n",
    "val_simple_dataset=SimpleDataset(val_prob_x,y_val)\n",
    "test_simple_dataset=SimpleDataset(test_prob_x)\n",
    "batch_size=2\n",
    "num_workers=2\n",
    "test_simple_dataloader = DataLoader(test_simple_dataset, batch_size=batch_size, shuffle=False,num_workers=num_workers,pin_memory=True)\n",
    "val_simple_dataloader = DataLoader(val_simple_dataset, batch_size=batch_size, shuffle=True,num_workers=num_workers,pin_memory=True,drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XlTqtiRntkO9",
    "outputId": "e8807d09-e643-4c44-94af-7202aafbad4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_simple_dataset[0][1].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKi7EtVyryYr"
   },
   "outputs": [],
   "source": [
    "\"\"\"def train():\n",
    "  try:\n",
    "    # Initialize a new wandb run\n",
    "    wandb.init()\n",
    "\n",
    "    # sweep agent inputs config with hyperparameters\n",
    "    config = wandb.config\n",
    "\n",
    "    #learning_rate = config.learning_rate\n",
    "    run_name = config.run_name #+f\"_{str(learning_rate)}learningRate\"\n",
    "    wandb.run.name = run_name\n",
    "\n",
    "    #num_epochs = 10\n",
    "\n",
    "    clf = RandomForestClassifier()\n",
    "\n",
    "    #clf.fit(train_x,y_train.ravel())\n",
    "    clf.fit(val_x,y_val.ravel())\n",
    "    #preds_val=clf.predict(val_x)\n",
    "    preds_test=clf.predict(test_x)\n",
    "\n",
    "    val_f1_macro = f1_score(y_val, preds_val,average=\"macro\")\n",
    "    val_f1_micro = f1_score(y_val, preds_val,average=\"micro\")\n",
    "    val_accuracy = accuracy_score(y_val, preds_val)\n",
    "    print({\"val_f1_macro\": val_f1_macro,\"val_f1_micro\":val_f1_micro, \"val_accuracy\": val_accuracy})\n",
    "    val_pred_labels=[num2label[el.item()] for el in preds_val]\n",
    "    val_dataset_=val_set.drop(columns=[\"label\",\"text\",\"image\"])\n",
    "    val_dataset_[\"label\"]=val_pred_labels\n",
    "    write_json(summary_dir_path,val_dataset_,\"val_preds.json\")\n",
    "\n",
    "\n",
    "    test_pred_labels=[num2label[el.item()] for el in preds_test]\n",
    "    dev_unlabeled_set_=dev_unlabeled_set.drop(columns=[\"text\",\"image\"])\n",
    "    dev_unlabeled_set_[\"label\"]=test_pred_labels\n",
    "    write_json(summary_dir_path,dev_unlabeled_set_,\"dev_preds.json\")\n",
    "\n",
    "    # Log metrics to W&B\n",
    "    wandb.log({\"val_f1_macro\": val_f1_macro,\"val_f1_micro\":val_f1_micro, \"val_accuracy\": val_accuracy})\n",
    "    summary = {\n",
    "    \"text_checkpoint\" : best_text_model,\n",
    "    \"img_checkpoint\":best_image_model,\n",
    "    \"best_meta_model\" : best_meta_model[\"best_meta\"],\n",
    "    \"train_path\" : train_path,\n",
    "    \"val_path\":val_path,\n",
    "    \"test_path\":test_path,\n",
    "    \"val_results\":{\"val_f1_macro\": val_f1_macro,\"val_f1_micro\":val_f1_micro, \"val_accuracy\": val_accuracy}\n",
    "    }\n",
    "    write_json(summary_dir_path,summary)\n",
    "    artifact = wandb.Artifact(f\"best_model_{run_name}\".replace(\"/\",\"_\"), type=\"model\")\n",
    "    artifact.add_file(folder_name+f\"best_model_{run_name}.pth\".replace(\"/\",\"_\"), pickle.dump(clf, open(folder_name+f\"best_model_{run_name}.pth\".replace(\"/\",\"_\"), 'wb')))\n",
    "    wandb.run.log_artifact(artifact)\n",
    "    os.remove(folder_name+f\"best_model_{run_name}.pth\".replace(\"/\",\"_\"))\n",
    "    drive_service.files().emptyTrash().execute()\n",
    "    wandb.finish()\n",
    "  except Exception as e:\n",
    "    print(f\"Error in training: {str(e)}\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ASo5_CiCHukV"
   },
   "outputs": [],
   "source": [
    "\"\"\"# Set hyperparams in sweep configurations\n",
    "run_name=f'{text_checkpoint}-{img_checkpoint}-subtask2b-STACKING'.replace(\"/\",\"_\")\n",
    "sweep_name=f'sweep_{run_name}'\n",
    "sweep_config = {\n",
    "    'method': 'grid',  # can be grid, random, or bayes\n",
    "    'name' : sweep_name,\n",
    "    'metric': {\n",
    "      'name': 'eval/f1_macro',\n",
    "      'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'run_name': {\n",
    "            'value' : run_name\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Start sweeps with specific configuration\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"subtask2b\")\n",
    "wandb.agent(sweep_id, train)\n",
    "# Get best model of sweep\n",
    "api = wandb.Api()\n",
    "sweep = api.sweep(f\"subtask2b/{sweep_id}\")\n",
    "best_run = sweep.best_run()\n",
    "\n",
    "artifacts = best_run.logged_artifacts()\n",
    "\n",
    "model_artifact = None\n",
    "for artifact in artifacts:\n",
    "    if 'model' in artifact.type:  # Adjust the condition based on your setup\n",
    "        model_artifact = artifact\n",
    "        break\n",
    "\n",
    "if model_artifact != None:\n",
    "  model_artifact_name = model_artifact.name\n",
    "  print(f\"Best Model: {model_artifact_name}\")\n",
    "else:\n",
    "  warnings.warn(f\"No models was found\")\n",
    "\n",
    "# save best model of this node\n",
    "best_meta_model[\"best_meta\"] = model_artifact_name\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7W6NVBJvuMUv"
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lh_JOgergpN3"
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "\n",
    "#clf.fit(train_x,y_train.ravel())\n",
    "clf.fit(val_x,y_val.ravel())\n",
    "#preds_val=clf.predict(val_x)\n",
    "preds_test=clf.predict(test_x)\n",
    "\n",
    "test_pred_labels=[num2label[el.item()] for el in preds_test]\n",
    "dev_unlabeled_set_=dev_unlabeled_set.drop(columns=[\"text\",\"image\"])\n",
    "dev_unlabeled_set_[\"label\"]=test_pred_labels\n",
    "write_json(summary_dir_path,dev_unlabeled_set_,\"dev_preds.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bBjM0hdjQN2-"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "\n",
    "#clf.fit(train_x,y_train.ravel())\n",
    "clf.fit(val_x,y_val.ravel())\n",
    "#preds_val=clf.predict(val_x)\n",
    "preds_test=clf.predict(test_x)\n",
    "\n",
    "test_pred_labels=[num2label[el.item()] for el in preds_test]\n",
    "dev_unlabeled_set_=dev_unlabeled_set.drop(columns=[\"text\",\"image\"])\n",
    "dev_unlabeled_set_[\"label\"]=test_pred_labels\n",
    "write_json(summary_dir_path,dev_unlabeled_set_,\"dev_preds_lr.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "x2d6lZeKkFnK"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "  try:\n",
    "    # Initialize a new wandb run\n",
    "    wandb.init()\n",
    "\n",
    "    # sweep agent inputs config with hyperparameters\n",
    "    config = wandb.config\n",
    "\n",
    "    learning_rate = config.learning_rate\n",
    "    run_name = config.run_name+f\"_{str(learning_rate)}learningRate\"\n",
    "    wandb.run.name = run_name\n",
    "\n",
    "    num_epochs = 50\n",
    "\n",
    "\n",
    "    # Instantiate the custom model\n",
    "    model=LinearLayers()\n",
    "    model.cuda()\n",
    "    loss_func = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    best_val_f1_macro=0.\n",
    "    best_train_f1_macro=0.\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        print(\"Started training epoch:\",epoch+1)\n",
    "        for x,y in val_simple_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            x=x.to(\"cuda\")\n",
    "            y=y.to(\"cuda\")\n",
    "            logits = model(x)\n",
    "            preds=sigmoid(logits)\n",
    "            loss = loss_func(logits.squeeze(), y.squeeze())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Collect predictions and labels for metrics calculation\n",
    "            preds_classes = (preds > 0.5).int().cpu().numpy()\n",
    "            all_preds.extend(preds_classes)\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "        average_loss = total_loss / len(val_simple_dataloader)\n",
    "\n",
    "        # Calculate and log F1 score and accuracy using sklearn metrics\n",
    "        f1_macro = f1_score(all_labels, all_preds,average=\"macro\")\n",
    "        f1_micro = f1_score(all_labels, all_preds,average=\"micro\")\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        # Log metrics to W&B\n",
    "        wandb.log({\"epoch\": epoch + 1, \"train_loss\": average_loss, \"f1_macro\": f1_macro, \"f1_micro\":f1_micro, \"train_accuracy\": accuracy})\n",
    "        print({\"epoch\": epoch + 1, \"train_loss\": average_loss, \"f1_macro\": f1_macro, \"f1_micro\":f1_micro, \"train_accuracy\": accuracy})\n",
    "\n",
    "        if f1_macro > best_train_f1_macro:\n",
    "          best_train_f1_macro=f1_macro\n",
    "          best_model_state_dict = model.state_dict()\n",
    "          wandb.log({\"eval/f1_macro\":f1_macro})\n",
    "\n",
    "        \"\"\"# Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_val_preds = []\n",
    "        all_val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for id, text_input, image_input, label in val_dataloader:\n",
    "                text_input = tokenizer(text_input, return_tensors=\"pt\",truncation=True, padding=True,max_length=512)\n",
    "\n",
    "                text_input=text_input.to(\"cuda\")\n",
    "                image_input['pixel_values']=image_input['pixel_values'].squeeze(1)\n",
    "                image_input=image_input.to(\"cuda\")\n",
    "                label=label.to(\"cuda\")\n",
    "                logits = model(text_input, image_input)\n",
    "                preds=sigmoid(logits)\n",
    "                val_loss += loss_func(logits.squeeze(), label).item()\n",
    "                # Collect predictions and labels for metrics calculation\n",
    "                val_preds_classes = (preds > 0.5).int().cpu().numpy()\n",
    "                all_val_preds.extend(val_preds_classes)\n",
    "                all_val_labels.extend(label.cpu().numpy())\n",
    "        average_val_loss = val_loss / len(val_dataloader)\n",
    "\n",
    "        # Calculate and log F1 score and accuracy for validation\n",
    "        val_f1_macro = f1_score(all_val_labels, all_val_preds,average=\"macro\")\n",
    "        val_f1_micro = f1_score(all_val_labels, all_val_preds,average=\"micro\")\n",
    "        val_accuracy = accuracy_score(all_val_labels, all_val_preds)\n",
    "        # Log metrics to W&B\n",
    "        wandb.log({\"epoch\": epoch + 1, \"val_loss\": average_val_loss, \"val_f1_macro\": val_f1_macro,\"val_f1_micro\":val_f1_micro, \"val_accuracy\": val_accuracy})\n",
    "\n",
    "        # Save the model if the current validation f1_macro is better than the previous best\n",
    "        if val_f1_macro > best_val_f1_macro:\n",
    "          best_val_f1_macro = val_f1_macro\n",
    "          best_model_state_dict = model.state_dict()\n",
    "          wandb.log({\"eval/f1_macro\":val_f1_macro})\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Training f1-macro: {f1_macro}, Validation f1-macro: {val_f1_macro}\")\n",
    "        model.train()\n",
    "        \"\"\"\n",
    "    # Finish W&B run\n",
    "\n",
    "    artifact = wandb.Artifact(f\"best_model_{run_name}\".replace(\"/\",\"_\"), type=\"model\")\n",
    "    artifact.add_file(folder_name+f\"best_model_{run_name}.pth\".replace(\"/\",\"_\"), torch.save(best_model_state_dict, folder_name+f\"best_model_{run_name}.pth\".replace(\"/\",\"_\")))\n",
    "    wandb.run.log_artifact(artifact)\n",
    "    os.remove(folder_name+f\"best_model_{run_name}.pth\".replace(\"/\",\"_\"))\n",
    "    #drive_service.files().emptyTrash().execute()\n",
    "    wandb.finish()\n",
    "  except Exception as e:\n",
    "    print(f\"Error in training: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "6f458b65185b4f518eb00518f2e30631",
      "a68f5d7610ba44b3bdb8a0eed9dbae63",
      "384d7eb1febf4d1d8fbc874cc6c4c45c",
      "96fa74bcfafc4abbba65c7ae3161a1d7",
      "92fa94cd08b14e399fb0705a73ea1b47",
      "c2dc044b679840849e583849c8181377",
      "2c4a3d2dd91c46ecbd4f59e11294507b",
      "f070bf2f2f62443f99dcaea17d095667",
      "0a079ab9bc304ac5a2b56cd75d2a6cb5",
      "4bd0a5bcbf754db2a7500f07438f877a",
      "48be6d478f78424b8293cada8dc21d98",
      "a2e3136c3a624af8b00112ecaf827b13",
      "835677851a654c88a9e3070646513e01",
      "342a9446469d433fa4bed97710228fb3",
      "99c0a0d7801647ceaf53f81addb31eea",
      "18f0ddc96f5e4442b39ce325c8d31b95"
     ]
    },
    "collapsed": true,
    "id": "tVDek86nkFyV",
    "outputId": "05c19da8-6a3c-4ced-c3fe-6be27ba6dab9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: nnxyfpwh\n",
      "Sweep URL: https://wandb.ai/tumnlp/subtask2b-LinearLayers/sweeps/nnxyfpwh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kgnswosw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trun_name: microsoft_deberta-v3-large-google_vit-base-patch32-224-in21k-subtask2b-STACKING-LinearLayers16Hid_Probs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nlp-lab-ws23/nlp_praktikum/persuasion_technique_detection/subtask2b/wandb/run-20240130_131806-kgnswosw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tumnlp/subtask2b-LinearLayers/runs/kgnswosw' target=\"_blank\">avid-sweep-1</a></strong> to <a href='https://wandb.ai/tumnlp/subtask2b-LinearLayers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/tumnlp/subtask2b-LinearLayers/sweeps/nnxyfpwh' target=\"_blank\">https://wandb.ai/tumnlp/subtask2b-LinearLayers/sweeps/nnxyfpwh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tumnlp/subtask2b-LinearLayers' target=\"_blank\">https://wandb.ai/tumnlp/subtask2b-LinearLayers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/tumnlp/subtask2b-LinearLayers/sweeps/nnxyfpwh' target=\"_blank\">https://wandb.ai/tumnlp/subtask2b-LinearLayers/sweeps/nnxyfpwh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tumnlp/subtask2b-LinearLayers/runs/kgnswosw' target=\"_blank\">https://wandb.ai/tumnlp/subtask2b-LinearLayers/runs/kgnswosw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training epoch: 1\n",
      "{'epoch': 1, 'train_loss': 0.6860279122988383, 'f1_macro': 0.4620734622908063, 'f1_micro': 0.56, 'train_accuracy': 0.56}\n",
      "Started training epoch: 2\n",
      "{'epoch': 2, 'train_loss': 0.659014474550883, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 3\n",
      "{'epoch': 3, 'train_loss': 0.6426870969931284, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 4\n",
      "{'epoch': 4, 'train_loss': 0.6324583240350088, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 5\n",
      "{'epoch': 5, 'train_loss': 0.625994401772817, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 6\n",
      "{'epoch': 6, 'train_loss': 0.6222893432776133, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 7\n",
      "{'epoch': 7, 'train_loss': 0.6197700798511505, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 8\n",
      "{'epoch': 8, 'train_loss': 0.6175986798604329, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 9\n",
      "{'epoch': 9, 'train_loss': 0.6160242815812429, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 10\n",
      "{'epoch': 10, 'train_loss': 0.613614350159963, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 11\n",
      "{'epoch': 11, 'train_loss': 0.6124411408106486, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 12\n",
      "{'epoch': 12, 'train_loss': 0.6106449488798777, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 13\n",
      "{'epoch': 13, 'train_loss': 0.6085761924584706, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 14\n",
      "{'epoch': 14, 'train_loss': 0.6073177699247996, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 15\n",
      "{'epoch': 15, 'train_loss': 0.6064867571989695, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 16\n",
      "{'epoch': 16, 'train_loss': 0.6061120351155599, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 17\n",
      "{'epoch': 17, 'train_loss': 0.6021802047888438, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 18\n",
      "{'epoch': 18, 'train_loss': 0.6010272387663523, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 19\n",
      "{'epoch': 19, 'train_loss': 0.5995050326983133, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 20\n",
      "{'epoch': 20, 'train_loss': 0.5985219550132751, 'f1_macro': 0.4416873449131513, 'f1_micro': 0.68, 'train_accuracy': 0.68}\n",
      "Started training epoch: 21\n",
      "{'epoch': 21, 'train_loss': 0.5986667239665985, 'f1_macro': 0.4805781391147244, 'f1_micro': 0.6933333333333334, 'train_accuracy': 0.6933333333333334}\n",
      "Started training epoch: 22\n",
      "{'epoch': 22, 'train_loss': 0.5957087965806326, 'f1_macro': 0.5343296512887157, 'f1_micro': 0.7133333333333335, 'train_accuracy': 0.7133333333333334}\n",
      "Started training epoch: 23\n",
      "{'epoch': 23, 'train_loss': 0.5944771281878154, 'f1_macro': 0.5511541749786264, 'f1_micro': 0.72, 'train_accuracy': 0.72}\n",
      "Started training epoch: 24\n",
      "{'epoch': 24, 'train_loss': 0.5927427450815836, 'f1_macro': 0.5252830719459878, 'f1_micro': 0.7, 'train_accuracy': 0.7}\n",
      "Started training epoch: 25\n",
      "{'epoch': 25, 'train_loss': 0.5928760333855947, 'f1_macro': 0.5479204339963835, 'f1_micro': 0.7, 'train_accuracy': 0.7}\n",
      "Started training epoch: 26\n",
      "{'epoch': 26, 'train_loss': 0.590172549088796, 'f1_macro': 0.5479204339963835, 'f1_micro': 0.7, 'train_accuracy': 0.7}\n",
      "Started training epoch: 27\n",
      "{'epoch': 27, 'train_loss': 0.5902083337306976, 'f1_macro': 0.55810147299509, 'f1_micro': 0.7, 'train_accuracy': 0.7}\n",
      "Started training epoch: 28\n",
      "{'epoch': 28, 'train_loss': 0.5885095600287119, 'f1_macro': 0.5431673728813559, 'f1_micro': 0.6933333333333334, 'train_accuracy': 0.6933333333333334}\n",
      "Started training epoch: 29\n",
      "{'epoch': 29, 'train_loss': 0.5870749159653982, 'f1_macro': 0.5431673728813559, 'f1_micro': 0.6933333333333334, 'train_accuracy': 0.6933333333333334}\n",
      "Started training epoch: 30\n",
      "{'epoch': 30, 'train_loss': 0.58715433994929, 'f1_macro': 0.5676125808724617, 'f1_micro': 0.7, 'train_accuracy': 0.7}\n",
      "Started training epoch: 31\n",
      "{'epoch': 31, 'train_loss': 0.5865866049130758, 'f1_macro': 0.55810147299509, 'f1_micro': 0.7, 'train_accuracy': 0.7}\n",
      "Started training epoch: 32\n",
      "{'epoch': 32, 'train_loss': 0.5871427841981252, 'f1_macro': 0.5676125808724617, 'f1_micro': 0.7, 'train_accuracy': 0.7}\n",
      "Started training epoch: 33\n",
      "{'epoch': 33, 'train_loss': 0.5859369627634684, 'f1_macro': 0.5726495726495726, 'f1_micro': 0.7066666666666667, 'train_accuracy': 0.7066666666666667}\n",
      "Started training epoch: 34\n",
      "{'epoch': 34, 'train_loss': 0.583100589911143, 'f1_macro': 0.5848453164401255, 'f1_micro': 0.7, 'train_accuracy': 0.7}\n",
      "Started training epoch: 35\n",
      "{'epoch': 35, 'train_loss': 0.5821280411879222, 'f1_macro': 0.5953322040278561, 'f1_micro': 0.7133333333333335, 'train_accuracy': 0.7133333333333334}\n",
      "Started training epoch: 36\n",
      "{'epoch': 36, 'train_loss': 0.582011973063151, 'f1_macro': 0.5953322040278561, 'f1_micro': 0.7133333333333335, 'train_accuracy': 0.7133333333333334}\n",
      "Started training epoch: 37\n",
      "{'epoch': 37, 'train_loss': 0.5815398879845937, 'f1_macro': 0.5848453164401255, 'f1_micro': 0.7, 'train_accuracy': 0.7}\n",
      "Started training epoch: 38\n",
      "{'epoch': 38, 'train_loss': 0.5810668500264485, 'f1_macro': 0.5796783625730995, 'f1_micro': 0.6933333333333334, 'train_accuracy': 0.6933333333333334}\n",
      "Started training epoch: 39\n",
      "{'epoch': 39, 'train_loss': 0.5811131076018016, 'f1_macro': 0.5848453164401255, 'f1_micro': 0.7, 'train_accuracy': 0.7}\n",
      "Started training epoch: 40\n",
      "{'epoch': 40, 'train_loss': 0.5809376831849417, 'f1_macro': 0.5848453164401255, 'f1_micro': 0.7, 'train_accuracy': 0.7}\n",
      "Started training epoch: 41\n",
      "{'epoch': 41, 'train_loss': 0.5826050261656444, 'f1_macro': 0.5796783625730995, 'f1_micro': 0.6933333333333334, 'train_accuracy': 0.6933333333333334}\n",
      "Started training epoch: 42\n",
      "{'epoch': 42, 'train_loss': 0.5796707761287689, 'f1_macro': 0.5796783625730995, 'f1_micro': 0.6933333333333334, 'train_accuracy': 0.6933333333333334}\n",
      "Started training epoch: 43\n",
      "{'epoch': 43, 'train_loss': 0.5782299323876698, 'f1_macro': 0.5745579627059321, 'f1_micro': 0.6866666666666666, 'train_accuracy': 0.6866666666666666}\n",
      "Started training epoch: 44\n",
      "{'epoch': 44, 'train_loss': 0.577518165508906, 'f1_macro': 0.5874192776847644, 'f1_micro': 0.6933333333333334, 'train_accuracy': 0.6933333333333334}\n",
      "Started training epoch: 45\n",
      "{'epoch': 45, 'train_loss': 0.5779616924126944, 'f1_macro': 0.5745579627059321, 'f1_micro': 0.6866666666666666, 'train_accuracy': 0.6866666666666666}\n",
      "Started training epoch: 46\n",
      "{'epoch': 46, 'train_loss': 0.5767568254470825, 'f1_macro': 0.5874192776847644, 'f1_micro': 0.6933333333333334, 'train_accuracy': 0.6933333333333334}\n",
      "Started training epoch: 47\n",
      "{'epoch': 47, 'train_loss': 0.5767337334156036, 'f1_macro': 0.6, 'f1_micro': 0.7, 'train_accuracy': 0.7}\n",
      "Started training epoch: 48\n",
      "{'epoch': 48, 'train_loss': 0.5784587009747824, 'f1_macro': 0.612312030075188, 'f1_micro': 0.7066666666666667, 'train_accuracy': 0.7066666666666667}\n",
      "Started training epoch: 49\n",
      "{'epoch': 49, 'train_loss': 0.5801987715562185, 'f1_macro': 0.5926618791865307, 'f1_micro': 0.7, 'train_accuracy': 0.7}\n",
      "Started training epoch: 50\n",
      "{'epoch': 50, 'train_loss': 0.5762012902895609, 'f1_macro': 0.5874192776847644, 'f1_micro': 0.6933333333333334, 'train_accuracy': 0.6933333333333334}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>eval/f1_macro</td><td>▁▂▄▅▅▆▆▇▇▇█</td></tr><tr><td>f1_macro</td><td>▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇</td></tr><tr><td>f1_micro</td><td>▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇██▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>train_accuracy</td><td>▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇██▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>train_loss</td><td>█▆▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>50</td></tr><tr><td>eval/f1_macro</td><td>0.61231</td></tr><tr><td>f1_macro</td><td>0.58742</td></tr><tr><td>f1_micro</td><td>0.69333</td></tr><tr><td>train_accuracy</td><td>0.69333</td></tr><tr><td>train_loss</td><td>0.5762</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">avid-sweep-1</strong> at: <a href='https://wandb.ai/tumnlp/subtask2b-LinearLayers/runs/kgnswosw' target=\"_blank\">https://wandb.ai/tumnlp/subtask2b-LinearLayers/runs/kgnswosw</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240130_131806-kgnswosw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yj2xa2yn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trun_name: microsoft_deberta-v3-large-google_vit-base-patch32-224-in21k-subtask2b-STACKING-LinearLayers16Hid_Probs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nlp-lab-ws23/nlp_praktikum/persuasion_technique_detection/subtask2b/wandb/run-20240130_131837-yj2xa2yn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tumnlp/subtask2b-LinearLayers/runs/yj2xa2yn' target=\"_blank\">clear-sweep-2</a></strong> to <a href='https://wandb.ai/tumnlp/subtask2b-LinearLayers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/tumnlp/subtask2b-LinearLayers/sweeps/nnxyfpwh' target=\"_blank\">https://wandb.ai/tumnlp/subtask2b-LinearLayers/sweeps/nnxyfpwh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tumnlp/subtask2b-LinearLayers' target=\"_blank\">https://wandb.ai/tumnlp/subtask2b-LinearLayers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/tumnlp/subtask2b-LinearLayers/sweeps/nnxyfpwh' target=\"_blank\">https://wandb.ai/tumnlp/subtask2b-LinearLayers/sweeps/nnxyfpwh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tumnlp/subtask2b-LinearLayers/runs/yj2xa2yn' target=\"_blank\">https://wandb.ai/tumnlp/subtask2b-LinearLayers/runs/yj2xa2yn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training epoch: 1\n",
      "{'epoch': 1, 'train_loss': 0.6671750132242839, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 2\n",
      "{'epoch': 2, 'train_loss': 0.6645925323168437, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 3\n",
      "{'epoch': 3, 'train_loss': 0.6622795804341635, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 4\n",
      "{'epoch': 4, 'train_loss': 0.6601470526059469, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 5\n",
      "{'epoch': 5, 'train_loss': 0.6580434823036194, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 6\n",
      "{'epoch': 6, 'train_loss': 0.6560798207918803, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 7\n",
      "{'epoch': 7, 'train_loss': 0.6541446232795716, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 8\n",
      "{'epoch': 8, 'train_loss': 0.652142809232076, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 9\n",
      "{'epoch': 9, 'train_loss': 0.6502778712908427, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 10\n",
      "{'epoch': 10, 'train_loss': 0.6484946060180664, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 11\n",
      "{'epoch': 11, 'train_loss': 0.6467888840039571, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 12\n",
      "{'epoch': 12, 'train_loss': 0.6451055224736532, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 13\n",
      "{'epoch': 13, 'train_loss': 0.6435144178072612, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 14\n",
      "{'epoch': 14, 'train_loss': 0.6419461814562479, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 15\n",
      "{'epoch': 15, 'train_loss': 0.6405440068244934, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 16\n",
      "{'epoch': 16, 'train_loss': 0.6391651233037313, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 17\n",
      "{'epoch': 17, 'train_loss': 0.6378224134445191, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 18\n",
      "{'epoch': 18, 'train_loss': 0.6365234486262004, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 19\n",
      "{'epoch': 19, 'train_loss': 0.6352896904945373, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 20\n",
      "{'epoch': 20, 'train_loss': 0.6341181759039561, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 21\n",
      "{'epoch': 21, 'train_loss': 0.6328970162073771, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 22\n",
      "{'epoch': 22, 'train_loss': 0.6318867520491283, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 23\n",
      "{'epoch': 23, 'train_loss': 0.6307941420873007, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 24\n",
      "{'epoch': 24, 'train_loss': 0.629827938079834, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 25\n",
      "{'epoch': 25, 'train_loss': 0.6288875937461853, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 26\n",
      "{'epoch': 26, 'train_loss': 0.6279426137606303, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 27\n",
      "{'epoch': 27, 'train_loss': 0.6271237425009409, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 28\n",
      "{'epoch': 28, 'train_loss': 0.626329904794693, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 29\n",
      "{'epoch': 29, 'train_loss': 0.6255685206254323, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 30\n",
      "{'epoch': 30, 'train_loss': 0.6248398315906525, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 31\n",
      "{'epoch': 31, 'train_loss': 0.6240943213303883, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 32\n",
      "{'epoch': 32, 'train_loss': 0.6234910889466604, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 33\n",
      "{'epoch': 33, 'train_loss': 0.6229013772805532, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 34\n",
      "{'epoch': 34, 'train_loss': 0.6222756115595499, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 35\n",
      "{'epoch': 35, 'train_loss': 0.6217396406332651, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 36\n",
      "{'epoch': 36, 'train_loss': 0.6213732194900513, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 37\n",
      "{'epoch': 37, 'train_loss': 0.6207002234458924, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 38\n",
      "{'epoch': 38, 'train_loss': 0.6201763733228047, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 39\n",
      "{'epoch': 39, 'train_loss': 0.6197579753398895, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 40\n",
      "{'epoch': 40, 'train_loss': 0.6192524270216624, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 41\n",
      "{'epoch': 41, 'train_loss': 0.6189192072550456, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 42\n",
      "{'epoch': 42, 'train_loss': 0.6184206795692444, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 43\n",
      "{'epoch': 43, 'train_loss': 0.6180225431919097, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 44\n",
      "{'epoch': 44, 'train_loss': 0.6176704180240631, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 45\n",
      "{'epoch': 45, 'train_loss': 0.6174209582805633, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 46\n",
      "{'epoch': 46, 'train_loss': 0.6169925018151601, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 47\n",
      "{'epoch': 47, 'train_loss': 0.6167477603753407, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 48\n",
      "{'epoch': 48, 'train_loss': 0.6163531974951426, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 49\n",
      "{'epoch': 49, 'train_loss': 0.6161755645275115, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n",
      "Started training epoch: 50\n",
      "{'epoch': 50, 'train_loss': 0.6159951933224996, 'f1_macro': 0.4, 'f1_micro': 0.6666666666666666, 'train_accuracy': 0.6666666666666666}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>eval/f1_macro</td><td>▁</td></tr><tr><td>f1_macro</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_micro</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>██▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>50</td></tr><tr><td>eval/f1_macro</td><td>0.4</td></tr><tr><td>f1_macro</td><td>0.4</td></tr><tr><td>f1_micro</td><td>0.66667</td></tr><tr><td>train_accuracy</td><td>0.66667</td></tr><tr><td>train_loss</td><td>0.616</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">clear-sweep-2</strong> at: <a href='https://wandb.ai/tumnlp/subtask2b-LinearLayers/runs/yj2xa2yn' target=\"_blank\">https://wandb.ai/tumnlp/subtask2b-LinearLayers/runs/yj2xa2yn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240130_131837-yj2xa2yn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sorting runs by -summary_metrics.eval/f1_macro\n",
      "<ipython-input-31-eade12e8bdd9>:41: UserWarning: No models was found\n",
      "  warnings.warn(f\"No models was found\")\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_artifact_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-eade12e8bdd9>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# save best model of this node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mbest_model_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_artifact_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_artifact_name' is not defined"
     ]
    }
   ],
   "source": [
    "# Set hyperparams in sweep configurations\n",
    "run_name=f'{text_checkpoint}-{img_checkpoint}-subtask2b-STACKING-LinearLayers16Hid_Probs'.replace(\"/\",\"_\")\n",
    "sweep_name=f'sweep_{run_name}'\n",
    "sweep_config = {\n",
    "    'method': 'grid',  # can be grid, random, or bayes\n",
    "    'name' : sweep_name,\n",
    "    'metric': {\n",
    "      'name': 'eval/f1_macro',\n",
    "      'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'learning_rate' : {\n",
    "            'values': [1e-3,1e-4]\n",
    "        },\n",
    "        'run_name': {\n",
    "            'value' : run_name\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Start sweeps with specific configuration\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"subtask2b-LinearLayers\")\n",
    "wandb.agent(sweep_id, train)\n",
    "# Get best model of sweep\n",
    "api = wandb.Api()\n",
    "sweep = api.sweep(f\"subtask2b-LinearLayers/{sweep_id}\")\n",
    "best_run = sweep.best_run()\n",
    "\n",
    "artifacts = best_run.logged_artifacts()\n",
    "\n",
    "model_artifact = None\n",
    "for artifact in artifacts:\n",
    "    if 'model' in artifact.type:  # Adjust the condition based on your setup\n",
    "        model_artifact = artifact\n",
    "        break\n",
    "\n",
    "if model_artifact != None:\n",
    "  model_artifact_name = model_artifact.name\n",
    "  print(f\"Best Model: {model_artifact_name}\")\n",
    "else:\n",
    "  warnings.warn(f\"No models was found\")\n",
    "\n",
    "# save best model of this node\n",
    "best_model_name = model_artifact_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "2IqxYKZvspEH"
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uPYGBWIo2btL",
    "outputId": "69965606-39a7-4f07-ef0b-a822290ba5cf"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-9138b9d0b673>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0martifact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0martifact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_state_dict_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pth\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_state_dict_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_model_name' is not defined"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "artifact=api.artifact(best_model_name)\n",
    "model_dir=artifact.download()\n",
    "model_state_dict_path = os.path.join(model_dir, best_model_name.split(\":\")[0]+\".pth\" )\n",
    "model_state_dict = torch.load(model_state_dict_path)\n",
    "model=LinearLayers()\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.cuda()\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OudVosGowCq"
   },
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "  for x in test_simple_dataloader:\n",
    "    x=x.to(\"cuda\")\n",
    "\n",
    "    logits = model(x)\n",
    "    preds=sigmoid(logits)\n",
    "\n",
    "    # Collect predictions and labels for metrics calculation\n",
    "    test_preds_classes = (preds > 0.5).int().cpu().numpy()\n",
    "    all_preds.extend(test_preds_classes)\n",
    "\n",
    "test_pred_labels=[num2label[el.item()] for el in all_preds]\n",
    "dev_unlabeled_set[\"label\"]=test_pred_labels\n",
    "#dev_unlabeled_set=dev_unlabeled_set.drop(columns=[\"text\",\"image\"])\n",
    "write_json(summary_dir_path,dev_unlabeled_set,\"dev_preds.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4a_2niCo2uWE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp_praktikum_env",
   "language": "python",
   "name": "nlp_praktikum_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a079ab9bc304ac5a2b56cd75d2a6cb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4bd0a5bcbf754db2a7500f07438f877a",
       "IPY_MODEL_48be6d478f78424b8293cada8dc21d98"
      ],
      "layout": "IPY_MODEL_a2e3136c3a624af8b00112ecaf827b13"
     }
    },
    "18f0ddc96f5e4442b39ce325c8d31b95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2c4a3d2dd91c46ecbd4f59e11294507b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "342a9446469d433fa4bed97710228fb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "384d7eb1febf4d1d8fbc874cc6c4c45c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c4a3d2dd91c46ecbd4f59e11294507b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f070bf2f2f62443f99dcaea17d095667",
      "value": 1
     }
    },
    "48be6d478f78424b8293cada8dc21d98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99c0a0d7801647ceaf53f81addb31eea",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_18f0ddc96f5e4442b39ce325c8d31b95",
      "value": 1
     }
    },
    "4bd0a5bcbf754db2a7500f07438f877a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_835677851a654c88a9e3070646513e01",
      "placeholder": "​",
      "style": "IPY_MODEL_342a9446469d433fa4bed97710228fb3",
      "value": "0.023 MB of 0.023 MB uploaded\r"
     }
    },
    "6f458b65185b4f518eb00518f2e30631": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a68f5d7610ba44b3bdb8a0eed9dbae63",
       "IPY_MODEL_384d7eb1febf4d1d8fbc874cc6c4c45c"
      ],
      "layout": "IPY_MODEL_96fa74bcfafc4abbba65c7ae3161a1d7"
     }
    },
    "835677851a654c88a9e3070646513e01": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92fa94cd08b14e399fb0705a73ea1b47": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96fa74bcfafc4abbba65c7ae3161a1d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99c0a0d7801647ceaf53f81addb31eea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2e3136c3a624af8b00112ecaf827b13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a68f5d7610ba44b3bdb8a0eed9dbae63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92fa94cd08b14e399fb0705a73ea1b47",
      "placeholder": "​",
      "style": "IPY_MODEL_c2dc044b679840849e583849c8181377",
      "value": "0.023 MB of 0.023 MB uploaded\r"
     }
    },
    "c2dc044b679840849e583849c8181377": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f070bf2f2f62443f99dcaea17d095667": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
