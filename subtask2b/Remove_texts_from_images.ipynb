{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WrE68K1hHfIH",
    "outputId": "6ddb2005-92ce-4d75-8ccf-1d6c4c24c4d7"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan  2 09:31:17 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080 Ti     On  | 00000000:2B:00.0 Off |                  N/A |\n",
      "|  0%   36C    P8              26W / 350W |      3MiB / 12288MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "e0qEUIF3H7TW"
   },
   "outputs": [],
   "source": [
    "folder_name = \"/home/nlp-lab-ws23/nlp_praktikum/persuasion_technique_detection/\" #\"/content/drive/MyDrive/persuasion_technique_detection/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z8vkc29OOJ4O",
    "outputId": "98c9624b-13fd-49c1-c68b-934472c3f054"
   },
   "outputs": [],
   "source": [
    "#!pip install keras-ocr --quiet\n",
    "#!pip install tensorflow\n",
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5R910yJgIGUS"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_ocr\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNkNvpDcICnF"
   },
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TzsReyNOH77b",
    "outputId": "fcd5b947-e633-401f-f3aa-bdd42751cc8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1199 150 300\n"
     ]
    }
   ],
   "source": [
    "val_path=\"data/subtask2b/val.json\"\n",
    "train_path=\"data/subtask2b/train.json\"\n",
    "test_path=\"data/subtask2b/dev_unlabeled.json\"\n",
    "\n",
    "with open(folder_name+val_path) as f:\n",
    "  d = json.load(f)\n",
    "  val=pd.DataFrame.from_dict(d)\n",
    "  labels=val[\"label\"]\n",
    "  num_label=[int(el==\"propagandistic\") for el in labels]\n",
    "  val[\"num_label\"]=num_label\n",
    "  val=val.drop(columns=['label'])\n",
    "  val_set=val.rename(columns={\"num_label\": \"label\"})\n",
    "\n",
    "with open(folder_name+train_path) as f:\n",
    "  d = json.load(f)\n",
    "  train=pd.DataFrame.from_dict(d)\n",
    "  labels=train[\"label\"]\n",
    "  num_label=[int(el==\"propagandistic\") for el in labels]\n",
    "  train[\"num_label\"]=num_label\n",
    "  train=train.drop(columns=['label'])\n",
    "  train_set=train.rename(columns={\"num_label\": \"label\"})\n",
    "  #mask = train_set['image'] == \"prop_meme_24871.png\"\n",
    "  #train_set = train_set[~mask]\n",
    "\n",
    "with open(folder_name+test_path) as f:\n",
    "  d = json.load(f)\n",
    "  dev_unlabeled_set=pd.DataFrame.from_dict(d)\n",
    "\n",
    "label2num={\"non_propagandistic\":0,\"propagandistic\":1}\n",
    "num2label={0:\"non_propagandistic\",1:\"propagandistic\"}\n",
    "\n",
    "print(len(train_set),len(val_set),len(dev_unlabeled_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zv3W1f5kIMrY"
   },
   "source": [
    "# Remove texts from images and save processed images\n",
    "Source: https://towardsdatascience.com/remove-text-from-images-using-cv2-and-keras-ocr-24e7612ae4f4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "eCMEgBN2IjpW"
   },
   "outputs": [],
   "source": [
    "def midpoint(x1, y1, x2, y2):\n",
    "    x_mid = int((x1 + x2) / 2)\n",
    "    y_mid = int((y1 + y2) / 2)\n",
    "    return (x_mid, y_mid)\n",
    "\n",
    "def inpaint_text(input_path, output_path, images, pipeline):\n",
    "    for image_name in images:\n",
    "        try:\n",
    "          img_path = os.path.join(input_path, image_name)  # Use os.path.join for path concatenation\n",
    "          img = keras_ocr.tools.read(img_path)\n",
    "          img_shape = img.shape\n",
    "          \n",
    "          prediction_groups = pipeline.recognize([img])\n",
    "          mask = np.zeros(img.shape[:2], dtype=\"uint8\")\n",
    "          for box in prediction_groups[0]:\n",
    "              x0, y0 = box[1][0]\n",
    "              x1, y1 = box[1][1]\n",
    "              x2, y2 = box[1][2]\n",
    "              x3, y3 = box[1][3]\n",
    "\n",
    "              x_mid0, y_mid0 = midpoint(x1, y1, x2, y2)\n",
    "              x_mid1, y_mid1 = midpoint(x0, y0, x3, y3)\n",
    "              thickness = int(math.sqrt((x2 - x1)**2 + (y2 - y1)**2))\n",
    "              cv2.line(mask, (x_mid0, y_mid0), (x_mid1, y_mid1), 255, thickness)\n",
    "          # Ensure the mask has the same dimensions as the image\n",
    "          mask = cv2.resize(mask, (img.shape[1], img.shape[0]))\n",
    "          img = cv2.inpaint(img, mask, 7, cv2.INPAINT_NS)\n",
    "          img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "          if not os.path.exists(output_path):\n",
    "              os.makedirs(output_path)\n",
    "\n",
    "          cv2.imwrite(os.path.join(output_path, image_name), img_rgb)\n",
    "        except Exception as e:\n",
    "          print(e,image_name)\n",
    "          continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FTW9KlefLktA",
    "outputId": "393471a4-ddce-42fa-eea6-310faa81e7ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for /home/nlp-lab-ws23/.keras-ocr/craft_mlt_25k.h5\n",
      "Looking for /home/nlp-lab-ws23/.keras-ocr/crnn_kurapan.h5\n"
     ]
    }
   ],
   "source": [
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "input_path=folder_name+\"data/subtask2b/subtask2b_images/train/\"\n",
    "output_path=folder_name+\"data/subtask2b/subtask2b_images_textsRemoved/train/\"\n",
    "inpaint_text(input_path,output_path,train_set[\"image\"],pipeline)\n",
    "input_path=folder_name+\"data/subtask2b/subtask2b_images/val/\"\n",
    "output_path=folder_name+\"data/subtask2b/subtask2b_images_textsRemoved/val/\"\n",
    "inpaint_text(input_path,output_path,val_set[\"image\"],pipeline)\n",
    "input_path=folder_name+\"data/subtask2b/subtask2b_images/dev/\"\n",
    "output_path=folder_name+\"data/subtask2b/subtask2b_images_textsRemoved/dev/\"\n",
    "inpaint_text(input_path,output_path,dev_unlabeled_set[\"image\"],pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prop_meme_2758.png', 'prop_meme_2723.png', '.ipynb_checkpoints'}\n"
     ]
    }
   ],
   "source": [
    "original=set(os.listdir(folder_name+\"data/subtask2b/subtask2b_images/train/\"))\n",
    "removed=set(os.listdir(folder_name+\"data/subtask2b/subtask2b_images_textsRemoved/train/\"))\n",
    "print(original-removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "original=set(os.listdir(folder_name+\"data/subtask2b/subtask2b_images/val/\"))\n",
    "removed=set(os.listdir(folder_name+\"data/subtask2b/subtask2b_images_textsRemoved/val/\"))\n",
    "print(original-removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "original=set(os.listdir(folder_name+\"data/subtask2b/subtask2b_images/dev/\"))\n",
    "removed=set(os.listdir(folder_name+\"data/subtask2b/subtask2b_images_textsRemoved/dev/\"))\n",
    "print(original-removed)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp_praktikum_env",
   "language": "python",
   "name": "nlp_praktikum_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
