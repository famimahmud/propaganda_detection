{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dU8lES-HiQHE"
   },
   "source": [
    "## Env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M_z85btlfVSY",
    "outputId": "09c8e604-9dc1-4a0d-f5a8-ad106a45dc85"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eKqXPIS-jWOf",
    "outputId": "a3929b0b-5f4d-45cb-9f00-7923396c07a3"
   },
   "outputs": [],
   "source": [
    "# For emptying trash after each run\n",
    "\"\"\"from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from googleapiclient.discovery import build\n",
    "drive_service = build('drive', 'v3')\n",
    "drive_service.files().emptyTrash().execute()\"\"\"\n",
    "!pwd\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fEoAZr2jdYV"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deheGLB8jglV"
   },
   "outputs": [],
   "source": [
    "folder_name = \"/home/nlp-lab-ws23/nlp_praktikum/persuasion_technique_detection/\" #\"/content/drive/MyDrive/persuasion_technique_detection/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WhEmv5JrjkZA",
    "outputId": "8e79c52e-347c-4d69-a5bc-f2a74616805e"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers datasets wandb evaluate accelerate -qU sklearn_hierarchical_classification sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_oAACjMfjnfd"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import subprocess\n",
    "import json\n",
    "import warnings\n",
    "import shutil\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer, ViTFeatureExtractor\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset,load_dataset,DatasetDict,concatenate_datasets\n",
    "import datasets\n",
    "import os\n",
    "from torch.nn.functional import sigmoid\n",
    "from datasets import concatenate_datasets\n",
    "from transformers import Trainer\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, ViTForImageClassification,AutoImageProcessor,AutoTokenizer,AutoFeatureExtractor,ViTImageProcessor,ViTConfig, BertConfig, VisionTextDualEncoderConfig, VisionTextDualEncoderModel,CLIPImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Esf7JoifjrV5",
    "outputId": "82f18e18-8dcd-4920-8528-304406e4d082"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "AVAIL_GPUS = 0\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    AVAIL_GPUS = torch.cuda.device_count()\n",
    "    print(f'There are {AVAIL_GPUS} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "namJ79hAjvvQ"
   },
   "source": [
    "## Login WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "qEAikZgDjtj5",
    "outputId": "804b4743-751b-464b-d6d7-23606ec6deae"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os\n",
    "\n",
    "#wandb.login(relogin=True)\n",
    "wandb.login()\n",
    "\n",
    "# setup wandb environment variables\n",
    "os.environ['WANDB_PROJECT'] = \"subtask2b\"\n",
    "os.environ['WANDB_ENTITY'] = \"tumnlp\"\n",
    "os.environ[\"WANDB_LOG_MODEL\"]= \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kd_G2X1-j1uB"
   },
   "outputs": [],
   "source": [
    "#text_checkpoint = \"vinai/bertweet-large\"\n",
    "img_checkpoint= \"google/vit-base-patch32-384\"\n",
    "# \"openai/clip-vit-base-patch32\" done\n",
    "# openai/clip-vit-base-patch16 done\n",
    "# google/vit-base-patch32-384 done\n",
    "#google/vit-base-patch32-224-in21k done\n",
    "# google/vit-base-patch16-384 done\n",
    "#'google/vit-base-patch16-224-in21k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-2F4_ljj6bu"
   },
   "outputs": [],
   "source": [
    "summary_dir_path = folder_name + \"subtask2b/new_summaries/summary_\" +img_checkpoint.replace(\"/\",\"_\")+\"_IMAGEONLY/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdDPD3uXkMWY"
   },
   "source": [
    "## Preprocess text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zXwsWCmbkQeT",
    "outputId": "a559954e-7453-4390-a1d4-82b625357fba"
   },
   "outputs": [],
   "source": [
    "val_path=\"data/subtask2b/val.json\"\n",
    "train_path=\"data/subtask2b/train.json\"\n",
    "test_path=\"data/subtask2b/dev_unlabeled.json\"\n",
    "\n",
    "with open(folder_name+val_path) as f:\n",
    "  d = json.load(f)\n",
    "  val=pd.DataFrame.from_dict(d)\n",
    "  labels=val[\"label\"]\n",
    "  num_label=[int(el==\"propagandistic\") for el in labels]\n",
    "  val[\"num_label\"]=num_label\n",
    "  val=val.drop(columns=['label'])\n",
    "  val_set=val.rename(columns={\"num_label\": \"label\"})\n",
    "\n",
    "with open(folder_name+train_path) as f:\n",
    "  d = json.load(f)\n",
    "  train=pd.DataFrame.from_dict(d)\n",
    "  labels=train[\"label\"]\n",
    "  num_label=[int(el==\"propagandistic\") for el in labels]\n",
    "  train[\"num_label\"]=num_label\n",
    "  train=train.drop(columns=['label'])\n",
    "  train_set=train.rename(columns={\"num_label\": \"label\"})\n",
    "  #mask = train_set['image'] == \"prop_meme_24871.png\"\n",
    "  #train_set = train_set[~mask]\n",
    "\n",
    "with open(folder_name+test_path) as f:\n",
    "  d = json.load(f)\n",
    "  dev_unlabeled_set=pd.DataFrame.from_dict(d)\n",
    "\n",
    "label2num={\"non_propagandistic\":0,\"propagandistic\":1}\n",
    "num2label={0:\"non_propagandistic\",1:\"propagandistic\"}\n",
    "\n",
    "print(len(train_set),len(val_set),len(dev_unlabeled_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V7sKojuVkswn"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, dataset_type,image_processor):\n",
    "        super().__init__()\n",
    "        self.ids=list(dataset[\"id\"])\n",
    "        self.texts = list(dataset[\"text\"])\n",
    "        self.image_paths = list(dataset[\"image\"])\n",
    "        if dataset_type==\"train\" or dataset_type==\"val\":\n",
    "          self.labels = dataset[\"label\"].astype(int).tolist()\n",
    "        self.image_processor = image_processor\n",
    "        self.dataset_type=dataset_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.dataset_type==\"train\":\n",
    "          image_path=folder_name+ \"data/subtask2b/subtask2b_images/train/\"+ self.image_paths[idx]\n",
    "        elif self.dataset_type==\"val\":\n",
    "          image_path=folder_name+ \"data/subtask2b/subtask2b_images/val/\"+ self.image_paths[idx]\n",
    "        else:\n",
    "          image_path=folder_name+ \"data/subtask2b/subtask2b_images/dev/\"+ self.image_paths[idx]\n",
    "\n",
    "        image_input = self.image_processor(images=Image.open(image_path).convert(\"RGB\"), return_tensors=\"pt\")\n",
    "\n",
    "        if self.dataset_type==\"train\" or self.dataset_type==\"val\":\n",
    "          label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "          return self.ids[idx],self.texts[idx],image_input,label\n",
    "        else:\n",
    "          return self.ids[idx],self.texts[idx],image_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Unw0tBzsyGU",
    "outputId": "449726e9-dd1b-448c-bab9-c9f89c564a7e"
   },
   "outputs": [],
   "source": [
    "# change image processor for different models\n",
    "image_processor = ViTImageProcessor.from_pretrained(img_checkpoint)  #'google/vit\n",
    "#image_processor = CLIPImageProcessor.from_pretrained(img_checkpoint) #\"openai/clip\n",
    "#image_processor = AutoImageProcessor.from_pretrained(img_checkpoint)\n",
    "#image_model = AutoModel.from_pretrained(img_checkpoint)\n",
    "image_model=ViTForImageClassification.from_pretrained(img_checkpoint)\n",
    "#image_model.config, text_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dO1VOZ8XqiiL"
   },
   "outputs": [],
   "source": [
    "# Create a custom dataset\n",
    "train_dataset = CustomDataset(train_set,\"train\", image_processor)\n",
    "val_dataset = CustomDataset(val_set,\"val\", image_processor)\n",
    "test_dataset = CustomDataset(dev_unlabeled_set,\"test\", image_processor)\n",
    "\n",
    "batch_size=2\n",
    "num_workers=2\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,num_workers=num_workers,pin_memory=True)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers=num_workers,pin_memory=True,drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,num_workers=num_workers,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aLh0NGcmazEG",
    "outputId": "06cd55c8-e865-4b66-83d7-7c8acfd74ced"
   },
   "outputs": [],
   "source": [
    "print(\"train size:\",len(train_set),\"val size:\",len(val_set),\"test size:\",len(dev_unlabeled_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIYgbiz9IBGr"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "difE4cnFJyls"
   },
   "outputs": [],
   "source": [
    "transfer_learning = False\n",
    "model_nodes = {\n",
    "    \"persuasion_or_not\":None}\n",
    "parent_nodes = {\n",
    "    \"persuasion_or_not\":\"persuasion_or_not\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKi7EtVyryYr"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "  try:\n",
    "    # Initialize a new wandb run\n",
    "    wandb.init()\n",
    "\n",
    "    # sweep agent inputs config with hyperparameters\n",
    "    config = wandb.config\n",
    "\n",
    "    learning_rate = config.learning_rate\n",
    "    run_name = config.run_name+f\"_{str(learning_rate)}learningRate\"\n",
    "    wandb.run.name = run_name\n",
    "\n",
    "    num_epochs = 10\n",
    "\n",
    "\n",
    "    image_model=ViTForImageClassification.from_pretrained(img_checkpoint)\n",
    "\n",
    "\n",
    "    image_model.cuda()\n",
    "\n",
    "    loss_func = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(image_model.parameters(), lr=learning_rate)\n",
    "    best_val_f1_macro=0.\n",
    "    for epoch in range(num_epochs):\n",
    "        image_model.train()\n",
    "        total_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        print(\"Started training epoch:\",epoch+1)\n",
    "        for id, text_input, image_input, label in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            image_input['pixel_values']=image_input['pixel_values'].squeeze(1)\n",
    "            image_input=image_input.to(\"cuda\")\n",
    "            label=label.to(\"cuda\")\n",
    "\n",
    "            outputs = image_model(**image_input)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            pred_logits,_=torch.max(logits,dim=1)\n",
    "            loss = loss_func(pred_logits, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Collect predictions and labels for metrics calculation\n",
    "            preds_classes = torch.argmax(logits,dim=1).cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds_classes)\n",
    "            all_labels.extend(label.cpu().numpy())\n",
    "\n",
    "        average_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        # Calculate and log F1 score and accuracy using sklearn metrics\n",
    "        f1_macro = f1_score(all_labels, all_preds,average=\"macro\")\n",
    "        f1_micro = f1_score(all_labels, all_preds,average=\"micro\")\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        # Log metrics to W&B\n",
    "        wandb.log({\"epoch\": epoch + 1, \"train_loss\": average_loss, \"f1_macro\": f1_macro, \"f1_micro\":f1_micro, \"train_accuracy\": accuracy})\n",
    "\n",
    "        # Validation\n",
    "        image_model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_val_preds = []\n",
    "        all_val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for id, text_input, image_input, label in val_dataloader:\n",
    "\n",
    "                image_input['pixel_values']=image_input['pixel_values'].squeeze(1)\n",
    "                image_input=image_input.to(\"cuda\")\n",
    "                label=label.to(\"cuda\")\n",
    "                outputs = image_model(**image_input)\n",
    "                logits = outputs.logits\n",
    "\n",
    "                pred_logits,_=torch.max(logits,dim=1)\n",
    "\n",
    "                val_loss += loss_func(pred_logits, label).item()\n",
    "                # Collect predictions and labels for metrics calculation\n",
    "                val_preds_classes = torch.argmax(logits,dim=1).cpu().numpy()\n",
    "                all_val_preds.extend(val_preds_classes)\n",
    "                all_val_labels.extend(label.cpu().numpy())\n",
    "        average_val_loss = val_loss / len(val_dataloader)\n",
    "\n",
    "        # Calculate and log F1 score and accuracy for validation\n",
    "        val_f1_macro = f1_score(all_val_labels, all_val_preds,average=\"macro\")\n",
    "        val_f1_micro = f1_score(all_val_labels, all_val_preds,average=\"micro\")\n",
    "        val_accuracy = accuracy_score(all_val_labels, all_val_preds)\n",
    "        # Log metrics to W&B\n",
    "        wandb.log({\"epoch\": epoch + 1, \"val_loss\": average_val_loss, \"val_f1_macro\": val_f1_macro,\"val_f1_micro\":val_f1_micro, \"val_accuracy\": val_accuracy})\n",
    "\n",
    "        # Save the model if the current validation f1_macro is better than the previous best\n",
    "        if val_f1_macro > best_val_f1_macro:\n",
    "          best_val_f1_macro = val_f1_macro\n",
    "          best_model_state_dict = image_model.state_dict()\n",
    "          wandb.log({\"eval/f1_macro\":val_f1_macro})\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Training f1-macro: {f1_macro}, Validation f1-macro: {val_f1_macro}\")\n",
    "        image_model.train()\n",
    "    # Finish W&B run\n",
    "\n",
    "    artifact = wandb.Artifact(f\"best_model_{run_name}\".replace(\"/\",\"_\"), type=\"model\")\n",
    "    artifact.add_file(folder_name+f\"best_model_{run_name}.pth\".replace(\"/\",\"_\"), torch.save(best_model_state_dict, folder_name+f\"best_model_{run_name}.pth\".replace(\"/\",\"_\")))\n",
    "    wandb.run.log_artifact(artifact)\n",
    "    os.remove(folder_name+f\"best_model_{run_name}.pth\".replace(\"/\",\"_\"))\n",
    "    #drive_service.files().emptyTrash().execute()\n",
    "    wandb.finish()\n",
    "  except Exception as e:\n",
    "    print(f\"Error in training: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ASo5_CiCHukV"
   },
   "outputs": [],
   "source": [
    "# Set hyperparams in sweep configurations\n",
    "run_name=f'{img_checkpoint}-subtask2b-memes-IMAGEONLY'.replace(\"/\",\"_\")\n",
    "sweep_name=f'sweep_{run_name}'\n",
    "sweep_config = {\n",
    "    'method': 'grid',  # can be grid, random, or bayes\n",
    "    'name' : sweep_name,\n",
    "    'metric': {\n",
    "      'name': 'eval/f1_macro',\n",
    "      'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'learning_rate' : {\n",
    "            'values': [1e-6,3e-6,5e-6,5e-5,5e-4]\n",
    "        },\n",
    "        'run_name': {\n",
    "            'value' : run_name\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Start sweeps with specific configuration\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"subtask2b\")\n",
    "wandb.agent(sweep_id, train)\n",
    "# Get best model of sweep\n",
    "api = wandb.Api()\n",
    "sweep = api.sweep(f\"subtask2b/{sweep_id}\")\n",
    "best_run = sweep.best_run()\n",
    "\n",
    "artifacts = best_run.logged_artifacts()\n",
    "\n",
    "model_artifact = None\n",
    "for artifact in artifacts:\n",
    "    if 'model' in artifact.type:  # Adjust the condition based on your setup\n",
    "        model_artifact = artifact\n",
    "        break\n",
    "\n",
    "if model_artifact != None:\n",
    "  model_artifact_name = model_artifact.name\n",
    "  print(f\"Best Model: {model_artifact_name}\")\n",
    "else:\n",
    "  warnings.warn(f\"No models was found\")\n",
    "\n",
    "# save best model of this node\n",
    "model_nodes[\"persuasion_or_not\"] = model_artifact_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7W6NVBJvuMUv"
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2g74zLLyO7Bl"
   },
   "source": [
    "## Eval on val set and save run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-TYPp7lO8NT"
   },
   "outputs": [],
   "source": [
    "def write_json(path,data,file_name=\"summary.json\"):\n",
    "  if not isinstance(data, dict):\n",
    "    data = data.to_dict(\"records\")\n",
    "  if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "  with open(path+file_name, \"w\") as output_file:\n",
    "      json.dump(data, output_file, indent=2,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fzHD9xsmO9qH",
    "outputId": "d9f1821a-35f1-4cba-bf8e-8caae6880bb1"
   },
   "outputs": [],
   "source": [
    "summary = {\n",
    "    \"img_checkpoint\":img_checkpoint,\n",
    "    \"model_nodes\" : model_nodes,\n",
    "    \"train_path\" : train_path,\n",
    "    \"val_path\":val_path,\n",
    "    \"test_path\":test_path\n",
    "}\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOpLTcyLa7J3"
   },
   "outputs": [],
   "source": [
    "write_json(summary_dir_path,summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8OUFdEpObOa"
   },
   "source": [
    "### Eval on val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xej5VYX6MRh3"
   },
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "artifact=api.artifact(model_nodes[\"persuasion_or_not\"])\n",
    "model_dir=artifact.download()\n",
    "model_state_dict_path = os.path.join(model_dir, model_nodes[\"persuasion_or_not\"].split(\":\")[0]+\".pth\" )\n",
    "model_state_dict = torch.load(model_state_dict_path)\n",
    "\n",
    "\n",
    "image_model=ViTForImageClassification.from_pretrained(img_checkpoint)\n",
    "image_model.load_state_dict(model_state_dict)\n",
    "image_model.cuda()\n",
    "\n",
    "image_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qVtL52LUMGOH",
    "outputId": "b42222f2-fd86-4157-df1e-2d2e36cbe75a"
   },
   "outputs": [],
   "source": [
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "val_loss = 0.0\n",
    "all_val_preds = []\n",
    "all_val_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for id, text_input, image_input, label in val_dataloader:\n",
    "\n",
    "        image_input['pixel_values']=image_input['pixel_values'].squeeze(1)\n",
    "        image_input=image_input.to(\"cuda\")\n",
    "        label=label.to(\"cuda\")\n",
    "\n",
    "        outputs = image_model(**image_input)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        pred_logits,_=torch.max(logits,dim=1)\n",
    "\n",
    "        val_loss += loss_func(pred_logits, label).item()\n",
    "\n",
    "        # Collect predictions and labels for metrics calculation\n",
    "        val_preds_classes = torch.argmax(logits,dim=1).cpu().numpy()\n",
    "        all_val_preds.extend(val_preds_classes)\n",
    "        all_val_labels.extend(label.cpu().numpy())\n",
    "\n",
    "average_val_loss = val_loss / len(val_dataloader)\n",
    "\n",
    "# Calculate and log F1 score and accuracy for validation\n",
    "val_f1_macro = f1_score(all_val_labels, all_val_preds,average=\"macro\")\n",
    "val_f1_micro = f1_score(all_val_labels, all_val_preds,average=\"micro\")\n",
    "val_accuracy = accuracy_score(all_val_labels, all_val_preds)\n",
    "val_results={\"f1_macro\":val_f1_macro,\"f1_micro\":val_f1_micro,\"val_accuracy\":val_accuracy}\n",
    "print(val_results)\n",
    "summary[\"val_results\"]=val_results\n",
    "print(summary)\n",
    "\n",
    "val_pred_labels=[num2label[el.item()] for el in all_val_preds]\n",
    "val_dataset_=val_set.drop(columns=[\"label\",\"text\",\"image\"])\n",
    "val_dataset_[\"label\"]=val_pred_labels\n",
    "write_json(summary_dir_path,val_dataset_,\"val_preds.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PmpeNtUXPFyU"
   },
   "outputs": [],
   "source": [
    "write_json(summary_dir_path, summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DE8G5_82PG19"
   },
   "outputs": [],
   "source": [
    "def delete_dir(path):\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            shutil.rmtree(path)\n",
    "            print(f\"The directory {path} and all its contents have been deleted successfully\")\n",
    "        except OSError as e:\n",
    "            print(f\"Error: {e.strerror}\")\n",
    "    else:\n",
    "        print(f\"The directory {path} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1WvHf-dhPNH6"
   },
   "outputs": [],
   "source": [
    "def delete_output_dirs(parent_directory):\n",
    "    for entry in os.listdir(parent_directory):\n",
    "        entry_path = os.path.join(parent_directory, entry)\n",
    "\n",
    "        if os.path.isdir(entry_path) and entry.startswith('output_'):\n",
    "            delete_dir(entry_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZsdOD9fIPP4H",
    "outputId": "0934ed8d-1578-44c4-ac59-520666385927"
   },
   "outputs": [],
   "source": [
    "path = folder_name + \"subtask2b\"\n",
    "delete_output_dirs(path)\n",
    "delete_dir(path + \"tumnlp\")\n",
    "delete_dir(path + \"wandb\")\n",
    "delete_dir(path + \"artifacts\")\n",
    "delete_dir(path + \"tmp_trainer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lvy5O3nzKpR7"
   },
   "source": [
    "## Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTg5HTjZOv8B"
   },
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "artifact=api.artifact(model_nodes[\"persuasion_or_not\"])\n",
    "model_dir=artifact.download()\n",
    "model_state_dict_path = os.path.join(model_dir, model_nodes[\"persuasion_or_not\"].split(\":\")[0]+\".pth\" )\n",
    "model_state_dict = torch.load(model_state_dict_path)\n",
    "\n",
    "\n",
    "image_model=ViTForImageClassification.from_pretrained(img_checkpoint)\n",
    "image_model.load_state_dict(model_state_dict)\n",
    "image_model.cuda()\n",
    "\n",
    "image_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zSOrYP8xO7Oi"
   },
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "  for id, text_input, image_input in test_dataloader:\n",
    "\n",
    "    image_input['pixel_values']=image_input['pixel_values'].squeeze(1)\n",
    "    image_input=image_input.to(\"cuda\")\n",
    "    outputs = image_model(**image_input)\n",
    "    logits = outputs.logits\n",
    "\n",
    "    # Collect predictions and labels for metrics calculation\n",
    "    test_preds_classes =  torch.argmax(logits,dim=1).cpu().numpy()\n",
    "    all_preds.extend(test_preds_classes)\n",
    "\n",
    "test_pred_labels=[num2label[el.item()] for el in all_preds]\n",
    "dev_unlabeled_set[\"label\"]=test_pred_labels\n",
    "dev_unlabeled_set=dev_unlabeled_set.drop(columns=[\"text\",\"image\"])\n",
    "write_json(summary_dir_path,dev_unlabeled_set,\"dev_preds.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KuLBGLoqQ3rY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp_praktikum_env",
   "language": "python",
   "name": "nlp_praktikum_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
